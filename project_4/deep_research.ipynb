{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0fb30d",
   "metadata": {},
   "source": [
    "# Project 4: **Build a Deep Research System**\n",
    "Welcome to project 4! For this project, we shift our focus from tool use and agents to *reasoning* models. You will practice state‑of‑the‑art inference‑time scaling methods such as *Chain‑of‑Thought* prompting and *Tree‑of‑Thoughts*, and briefly explore high-levels of training reasoning models using techniques like **STaR**.\n",
    "\n",
    "\n",
    "Finally, you will put everything together to build a *deep research agent* that can browse the web, reason over what it finds, and give structured answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54845369",
   "metadata": {},
   "source": [
    "## Learning Objectives  \n",
    "* Apply common inference‑time scaling methods: **zero‑shot / few‑shot CoT, self‑consistency, sequential decoding, tree‑of‑thoughts**  \n",
    "* Gain intuition for **training** reasoning‑capable models following **STaR** approach \n",
    "* Build a minimal **deep‑research agent** that combines step‑by‑step reasoning with live web search   \n",
    "* Practice extending deep-search to a multi-agent system "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a40a86",
   "metadata": {},
   "source": [
    "## Roadmap  \n",
    "1. Environment setup  \n",
    "2. Inference‑time scaling  \n",
    "   2.1 Few‑shot & zero‑shot CoT  \n",
    "   2.2 Self‑consistency\n",
    "   2.3 Sequential revisions  \n",
    "   2.4 Tree‑of‑Thought\n",
    "3. STaR for training models for reasoning  \n",
    "4. Deep-research agent  \n",
    "5. (Optional) Multi-agent deep-research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e480f76",
   "metadata": {},
   "source": [
    "# 1‑ Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c2218",
   "metadata": {},
   "source": [
    "## 1.1- Conda environment\n",
    "\n",
    "Before we start coding, you need a reproducible setup. Open a terminal in the same directory as this notebook and run:\n",
    "\n",
    "```bash\n",
    "# Create and activate the conda environment\n",
    "conda env create -f environment.yaml && conda activate deep_research\n",
    "\n",
    "# Register this environment as a Jupyter kernel\n",
    "python -m ipykernel install --user --name=deep_research --display-name \"deep_research\"\n",
    "```\n",
    "Once this is done, you can select \"deep_research\" from the Kernel → Change Kernel menu in Jupyter or VS Code.\n",
    "\n",
    "## 1.2 Ollama setup\n",
    "\n",
    "In this project we use the `llama3.2:3b` and `deepseek-r1:8b` models. You can try other smaller or larger reasoning LLMs such as `qwen2.5:3b-instruct` or `phi4-mini` to compare performance. Explore available models here: https://ollama.com/library.\n",
    "\n",
    "```bash\n",
    "ollama pull llama3.2:3b\n",
    "ollama pull deepseek-r1:8b\n",
    "# Additional small reasoning models to compare\n",
    "# ollama pull qwen2.5:3b-instruct\n",
    "# ollama pull phi4-mini\n",
    "\n",
    "```\n",
    "\n",
    "`ollama pull` downloads the model so you can run it locally without API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8d1b7",
   "metadata": {},
   "source": [
    "---  \n",
    "# 2‑ Inference‑time scaling\n",
    "\n",
    "Inference-time scaling refers to techniques that make an existing model reason better without retraining it. Instead of changing the model’s weights, we achieve reasoning capability by adjusting how we prompt, sample, or aggregate LLM's outputs.\n",
    "\n",
    "In this section, we’ll explore several inference-time strategies that improve reasoning quality using a non-reasoning base model. You will experiment with and compare methods such as:\n",
    "\n",
    "- Few-shot Chain-of-Thought (CoT)\n",
    "- Zero-shot CoT\n",
    "- Self-consistency\n",
    "- Sequential revision\n",
    "- Tree-of-Thoughts (ToT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d499a",
   "metadata": {},
   "source": [
    "### 2.1: Few‑Shot CoT\n",
    "Few-shot prompting helps a model reason by showing one or multiple examples before asking a new question. By observing the pattern of reasoning and final answers, the model learns how to structure its own reasoning process on the new input.\n",
    "\n",
    "In this exercise, you will create a prompt that includes a few example Q&A pairs demonstrating step-by-step reasoning. Then, you will feed a new question and see the model’s output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173d73f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's reasoning:\n",
      "To find the area of a square with a given perimeter, we need to follow these steps:\n",
      "\n",
      "1. The formula for the perimeter of a square is P = 4s, where s is the length of one side.\n",
      "2. Given that the perimeter is 20 cm, we can set up an equation as follows: 20 = 4s\n",
      "3. To find the value of s, divide both sides by 4: s = 20 / 4 = 5 cm\n",
      "4. Now that we know the length of one side (s) is 5 cm, we can use the formula for the area of a square: A = s^2\n",
      "5. Therefore, the area of the square is A = (5)^2 = 25 cm^2\n",
      "\n",
      "Answer: The area of the square is 25 cm^2\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client for Ollama\n",
    "client = OpenAI(api_key=\"ollama\", base_url=\"http://localhost:11434/v1\")\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "# Create few-shot examples with step-by-step reasoning\n",
    "few_shot_prompt = \"\"\"\n",
    "Question: If Mary has 3 apples and gives 1 to John, how many apples does she have left?\n",
    "Let's solve this step by step:\n",
    "1. Initially, Mary has 3 apples\n",
    "2. She gives 1 apple to John\n",
    "3. Therefore, 3 - 1 = 2 apples remain\n",
    "Answer: 2 apples\n",
    "\n",
    "Question: A train travels 120 km in 2 hours. What is its average speed?\n",
    "Let's solve this step by step:\n",
    "1. Distance traveled = 120 km\n",
    "2. Time taken = 2 hours\n",
    "3. Average speed = Distance ÷ Time\n",
    "4. Therefore, 120 ÷ 2 = 60\n",
    "Answer: 60 kilometers per hour\n",
    "\n",
    "Question: If a square has a perimeter of 20 cm, what is its area?\n",
    "Let's think step by step:\"\"\"\n",
    "\n",
    "# Call the model with few-shot examples\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": few_shot_prompt}],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Model's reasoning:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e29d9",
   "metadata": {},
   "source": [
    "### (Optional) Few-shot CoT on GPT2\n",
    "GPT-2 is a pre-trained language model without instruction tuning. It continues text rather than answering questions. In this section, you'll try the exact same CoT pattern on GPT-2 and observe what happens. The goal is to test whether few-shot CoT alone can elicit structured reasoning from a non-chat LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8af711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GPT-2's reasoning ability with different decoding strategies:\n",
      "\n",
      "\n",
      "Greedy (greedy decoding):\n",
      "--------------------------------------------------\n",
      "1. Student = 1 pencil\n",
      "\n",
      "2. Student = 2 pencils\n",
      "\n",
      "3. Student = 3 pencils\n",
      "\n",
      "Answer: 3 pencils\n",
      "\n",
      "Q: If I have 2 cookies and eat 1, how many do I have?\n",
      "\n",
      "Steps:\n",
      "\n",
      "1. Start with 2 cookies\n",
      "\n",
      "2. Eat 1 cookie\n",
      "\n",
      "3. 2 - 1 = 1 cookie left\n",
      "\n",
      "Answer: 1 cookie\n",
      "\n",
      "Q: A rectangle is 4m wide and\n",
      "\n",
      "Sampling (temperature=0.7):\n",
      "--------------------------------------------------\n",
      "15 students share 45 pencils equally\n",
      "\n",
      "Q: If I have 5 pencils, how many do I get?\n",
      "\n",
      "Steps:\n",
      "\n",
      "5 pencils\n",
      "\n",
      "Q: If I have 10 pencils, how many do I get?\n",
      "\n",
      "Steps:\n",
      "\n",
      "10 pencils\n",
      "\n",
      "Q: If I have 2 pencils, how many do I get?\n",
      "\n",
      "Steps:\n",
      "\n",
      "2 pencils\n",
      "\n",
      "Q: If I have 3 pencils\n",
      "\n",
      "Top-k sampling (k=50):\n",
      "--------------------------------------------------\n",
      "1. 15 students = 1 pencil\n",
      "\n",
      "2. 15 students = 2 pencils\n",
      "\n",
      "3. 15 students = 3 pencils\n",
      "\n",
      "\n",
      "Q: I didn't pay for the class! What should I do?\n",
      "\n",
      "Steps:\n",
      "\n",
      "1. Make sure you're not going to lose my money.\n",
      "\n",
      "2. Pay for tuition and fees.\n",
      "\n",
      "3. Make sure you're in good shape.\n",
      "\n",
      "4. Don't feel bad for the person you\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize GPT-2 pipeline with text-generation\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Create a few-shot prompt with simpler examples (since GPT-2 has limited context)\n",
    "few_shot_prompt = \"\"\"\n",
    "Q: If I have 2 cookies and eat 1, how many do I have?\n",
    "Steps:\n",
    "1. Start with 2 cookies\n",
    "2. Eat 1 cookie\n",
    "3. 2 - 1 = 1 cookie left\n",
    "Answer: 1 cookie\n",
    "\n",
    "Q: A rectangle is 4m wide and 3m long. What's the area?\n",
    "Steps:\n",
    "1. Area = width × length\n",
    "2. Area = 4m × 3m\n",
    "3. Area = 12 square meters\n",
    "Answer: 12 square meters\n",
    "\n",
    "Q: If 15 students share 45 pencils equally, how many pencils does each student get?\n",
    "Steps:\"\"\"\n",
    "\n",
    "# Generate completions with different decoding settings\n",
    "outputs = []\n",
    "\n",
    "# Greedy decoding (no sampling)\n",
    "greedy = generator(few_shot_prompt, max_new_tokens=100, num_return_sequences=1, pad_token_id=50256, do_sample=False)\n",
    "outputs.append((\"Greedy (greedy decoding):\", greedy[0]['generated_text']))\n",
    "\n",
    "# Sampling with temperature\n",
    "sampled = generator(few_shot_prompt, max_new_tokens=100, num_return_sequences=1,\n",
    "                   temperature=0.7, pad_token_id=50256)\n",
    "outputs.append((\"Sampling (temperature=0.7):\", sampled[0]['generated_text']))\n",
    "\n",
    "# Top-k sampling\n",
    "top_k = generator(few_shot_prompt, max_new_tokens=100, num_return_sequences=1,\n",
    "                 temperature=0.7, top_k=50, pad_token_id=50256)\n",
    "outputs.append((\"Top-k sampling (k=50):\", top_k[0]['generated_text']))\n",
    "\n",
    "# Print and compare outputs\n",
    "print(\"Testing GPT-2's reasoning ability with different decoding strategies:\\n\")\n",
    "for method, output in outputs:\n",
    "    print(f\"\\n{method}\")\n",
    "    print(\"-\" * 50)\n",
    "    # Print only the new content after our prompt\n",
    "    new_content = output[len(few_shot_prompt):]\n",
    "    print(new_content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adee0e7",
   "metadata": {},
   "source": [
    "### 2.2: Zero‑Shot Chain‑of‑Thought\n",
    "Zero-shot CoT encourages the model to reason without examples by adding a short cue such as “Let’s think step by step.” This simple phrase often activates the model’s latent reasoning ability even when no demonstrations are provided. It serves as a baseline to compare with few-shot and other inference-time scaling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c444eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: In a class of 24 students, 3/4 play sports and 2/3 of those who play sports also play music. How many students play both sports and music?\n",
      "\n",
      "Reasoning process:\n",
      "We can break down the problem into smaller steps to find out how many students play both sports and music.\n",
      "\n",
      "Step 1: Find the number of students who play sports.\n",
      "Since 3/4 of the students play sports, we need to multiply the total number of students (24) by 3/4:\n",
      "\n",
      "Number of students who play sports = 24 x 3/4\n",
      "= 24 x 0.75\n",
      "= 18\n",
      "\n",
      "So, 18 students play sports.\n",
      "\n",
      "Step 2: Find the number of students who play both sports and music.\n",
      "Since 2/3 of those who play sports also play music, we need to multiply the number of students who play sports (18) by 2/3:\n",
      "\n",
      "Number of students who play both sports and music = 18 x 2/3\n",
      "= 18 x 0.67\n",
      "= 12\n",
      "\n",
      "Therefore, 12 students play both sports and music.\n",
      "\n",
      "Let me know if you have any further questions or need help with anything else!\n",
      "We can break down the problem into smaller steps to find out how many students play both sports and music.\n",
      "\n",
      "Step 1: Find the number of students who play sports.\n",
      "Since 3/4 of the students play sports, we need to multiply the total number of students (24) by 3/4:\n",
      "\n",
      "Number of students who play sports = 24 x 3/4\n",
      "= 24 x 0.75\n",
      "= 18\n",
      "\n",
      "So, 18 students play sports.\n",
      "\n",
      "Step 2: Find the number of students who play both sports and music.\n",
      "Since 2/3 of those who play sports also play music, we need to multiply the number of students who play sports (18) by 2/3:\n",
      "\n",
      "Number of students who play both sports and music = 18 x 2/3\n",
      "= 18 x 0.67\n",
      "= 12\n",
      "\n",
      "Therefore, 12 students play both sports and music.\n",
      "\n",
      "Let me know if you have any further questions or need help with anything else!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client for Ollama\n",
    "client = OpenAI(api_key=\"ollama\", base_url=\"http://localhost:11434/v1\")\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def zero_shot_cot(question: str, temperature: float = 0.7) -> str:\n",
    "    # Create a zero-shot prompt with reasoning cue\n",
    "    prompt = f\"\"\"You are a helpful expert assistant. Please help solve this problem step by step:\n",
    "\n",
    "{question}\n",
    "\n",
    "Let's approach this step by step:\"\"\"\n",
    "    \n",
    "    # Call the model\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test with a challenging multi-step problem\n",
    "question = \"In a class of 24 students, 3/4 play sports and 2/3 of those who play sports also play music. How many students play both sports and music?\"\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"\\nReasoning process:\")\n",
    "print(zero_shot_cot(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686708da",
   "metadata": {},
   "source": [
    "### 2.3 Self‑Consistency\n",
    "Self-consistency enhances reasoning accuracy by sampling multiple independent reasoning paths for the same question instead of relying on a single deterministic answer. Each run may follow a slightly different logical chain, and the diversity helps correct individual mistakes. After generating several reasoning traces, you then aggregate the final answers using majority voting.\n",
    "\n",
    "This approach is especially useful when tasks involve multi-step reasoning or arithmetic, where single-path outputs may be incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2fb325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Votes: Counter({'The square root of 144 is 12.': 2, 'with no fractional component when squared, look at the pair:': 1, 'must be somewhere between 12 and 14.': 1, '12': 1, 'The value of the square root of 144 is 12.': 1})\n",
      "Chosen answer: The square root of 144 is 12.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import re, collections\n",
    "\n",
    "# Initialize Ollama/OpenAI-compatible client\n",
    "client = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "\n",
    "def cot_answer(question: str, temperature: float = 1.0) -> str:\n",
    "    \"\"\"Generate a chain-of-thought trace for `question` and return the final answer string.\n",
    "\n",
    "    - Builds a short prompt that cues step-by-step reasoning.\n",
    "    - Calls the chat completions API.\n",
    "    - Extracts the final answer heuristically by looking for an `Answer:` line or the last non-empty line.\n",
    "\n",
    "    Returns:\n",
    "        final_ans (str): extracted final answer (trimmed). If parsing fails, returns the full model output.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a helpful assistant. Please answer the question step-by-step and finish with a clear final line prefixed with 'Answer:'\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Let's think step by step:\"\"\"\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        content = resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        # Return a sentinel so the caller can handle failures\n",
    "        return f\"<ERROR: {e}>\"\n",
    "\n",
    "    # Try to extract text after 'Answer:' (case-insensitive)\n",
    "    m = re.search(r\"Answer\\s*[:\\-]?\\s*(.+)$\", content, flags=re.IGNORECASE | re.MULTILINE)\n",
    "    if m:\n",
    "        final = m.group(1).strip()\n",
    "        # If answer spans multiple lines, take up to the first blank line\n",
    "        final_lines = [l for l in final.splitlines() if l.strip()]\n",
    "        return final_lines[0].strip() if final_lines else final.strip()\n",
    "\n",
    "    # Fallback: take the last non-empty line of the model output\n",
    "    lines = [l.strip() for l in content.splitlines() if l.strip()]\n",
    "    if lines:\n",
    "        return lines[-1]\n",
    "\n",
    "    # If everything else fails return the raw content\n",
    "    return content\n",
    "\n",
    "\n",
    "def self_consistent(question: str, n: int = 10, base_temperature: float = 0.8) -> tuple:\n",
    "    \"\"\"Run `cot_answer` n times (with sampling) and return the most common final answer plus the Counter.\n",
    "\n",
    "    Args:\n",
    "        question: the question string\n",
    "        n: number of sampled reasoning traces to generate\n",
    "        base_temperature: sampling temperature for diversity (set near 0 for deterministic)\n",
    "\n",
    "    Returns:\n",
    "        (winner, counter): winner is the most-common answer string; counter is a collections.Counter of all answers\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "    for i in range(n):\n",
    "        # increase temperature slightly for more diversity across runs\n",
    "        temp = base_temperature if i > 0 else max(0.2, base_temperature - 0.2)\n",
    "        ans = cot_answer(question, temperature=temp)\n",
    "        answers.append(ans)\n",
    "\n",
    "    counter = collections.Counter(answers)\n",
    "    if not counter:\n",
    "        return None, counter\n",
    "\n",
    "    winner = counter.most_common(1)[0][0]\n",
    "    return winner, counter\n",
    "\n",
    "\n",
    "# Small demonstration/test (runs in notebook)\n",
    "question = \"What is the square root of 144?\"\n",
    "winner, counter = self_consistent(question, n=6, base_temperature=0.8)\n",
    "print(\"Votes:\", counter)\n",
    "print(\"Chosen answer:\", winner)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bea715",
   "metadata": {},
   "source": [
    "### 2.4: Sequential Revision\n",
    "\n",
    "Sequential revision iteratively improves an answer by generating a first draft, critiquing it, and producing revised drafts that condition on prior answers. Each round should be short and focused, so improvements accumulate without drifting from the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e5859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft 1:\n",
      " **Activity Title:** \"Rolling with Probability\"\n",
      "\n",
      "**Objective:** To introduce 8th graders to the concept of probability and its application in real-life situations through a hands-on activity.\n",
      "\n",
      "**Materials:**\n",
      "\n",
      "* A standard six-sided die (d6)\n",
      "* Whiteboard or chalkboard\n",
      "* Markers or chalk\n",
      "* Printed copies of the probability formula (P = number of favorable outcomes / total number of possible outcomes)\n",
      "\n",
      "**Step-by-Step Procedure:**\n",
      "\n",
      "1. Introduction (5 minutes):\n",
      "\t* Introduce the concept of probability and ask students if they have ever heard of it.\n",
      "\t* Write the definition on the board: \"Probability is a measure of how likely an event is to occur.\"\n",
      "2. Direct Instruction (10 minutes):\n",
      "\t* Explain that probability can be calculated using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "\t* Use simple examples, such as flipping a coin or rolling a die, to illustrate the concept.\n",
      "\t* Write the formula on the board and have students copy it onto their printed copies.\n",
      "3. Guided Practice (20 minutes):\n",
      "\t* Divide the class into small groups of 3-4 students.\n",
      "\t* Give each group a set of questions related to probability, such as:\n",
      "\t\t+ What is the probability of rolling an even number on a d6?\n",
      "\t\t+ What is the probability of drawing a heart from a standard deck of cards?\n",
      "\t* Have each group work together to calculate the probabilities using the formula.\n",
      "\t* Circulate around the room to assist and provide feedback.\n",
      "4. Independent Practice (15 minutes):\n",
      "\t* Provide students with a blank sheet of paper and ask them to design their own probability experiment, such as rolling different types of dice or drawing cards from a deck.\n",
      "\t* Encourage students to calculate the probabilities for their experiment using the formula.\n",
      "5. Conclusion (10 minutes):\n",
      "\t* Have each group present their findings and discuss any common misconceptions or misunderstandings.\n",
      "\t* Review the key concepts learned during the activity, including the probability formula and its application.\n",
      "\n",
      "**Expected Learning Outcomes:**\n",
      "\n",
      "* Students will understand the concept of probability and its relationship to chance events.\n",
      "* Students will be able to calculate probabilities using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "* Students will apply probability concepts to real-life situations through a hands-on experiment.\n",
      "\n",
      "**Assessment:**\n",
      "\n",
      "* Observe student participation during the activity and assess their understanding through group presentations.\n",
      "* Review student worksheets for accuracy and completeness.\n",
      "* Use a rubric to evaluate student experiments and provide feedback.\n",
      "\n",
      "Draft 2:\n",
      "**Activity Title:** \"Rolling with Probability\"\n",
      "\n",
      "**Objective:** To introduce 8th graders to the concept of probability and its application in real-life situations through a hands-on activity.\n",
      "\n",
      "**Materials:**\n",
      "\n",
      "* A standard six-sided die (d6)\n",
      "* Whiteboard or chalkboard\n",
      "* Markers or chalk\n",
      "* Printed copies of the probability formula (P = number of favorable outcomes / total number of possible outcomes)\n",
      "\n",
      "**Step-by-Step Procedure:**\n",
      "\n",
      "1. Introduction (5 minutes):\n",
      "\t* Introduce the concept of probability and ask students if they have ever heard of it.\n",
      "\t* Write the definition on the board: \"Probability is a measure of how likely an event is to occur.\"\n",
      "2. Direct Instruction (10 minutes):\n",
      "\t* Explain that probability can be calculated using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "\t* Use simple examples, such as flipping a coin or rolling a die, to illustrate the concept.\n",
      "\t* Write the formula on the board and have students copy it onto their printed copies.\n",
      "3. Guided Practice (20 minutes):\n",
      "\t* Divide the class into small groups of 3-4 students.\n",
      "\t* Give each group a set of questions related to probability, such as:\n",
      "\t\t+ What is the probability of rolling an even number on a d6?\n",
      "\t\t+ What is the probability of drawing a heart from a standard deck of cards?\n",
      "\t* Have each group work together to calculate the probabilities using the formula.\n",
      "\t* Circulate around the room to assist and provide feedback.\n",
      "4. Independent Practice (15 minutes):\n",
      "\t* Provide students with a blank sheet of paper and ask them to design their own probability experiment, such as rolling different types of dice or drawing cards from a deck.\n",
      "\t* Encourage students to calculate the probabilities for their experiment using the formula.\n",
      "5. Conclusion (10 minutes):\n",
      "\t* Have each group present their findings and discuss any common misconceptions or misunderstandings.\n",
      "\t* Review the key concepts learned during the activity, including the probability formula and its application.\n",
      "\n",
      "**Expected Learning Outcomes:**\n",
      "\n",
      "* Students will understand the concept of probability and its relationship to chance events.\n",
      "* Students will be able to calculate probabilities using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "* Students will apply probability concepts to real-life situations through a hands-on experiment.\n",
      "\n",
      "**Assessment:**\n",
      "\n",
      "* Observe student participation during the activity and assess their understanding through group presentations.\n",
      "* Review student worksheets for accuracy and completeness.\n",
      "* Use a rubric to evaluate student experiments and provide feedback.\n",
      "\n",
      "**Main Weaknesses:**\n",
      "The only weakness in this draft is that there is no clear evaluation of student learning outcomes. Adding more specific language in the expected learning outcomes section would make it clearer what students are expected to learn from the activity.\n",
      "\n",
      "**Revised Draft:**\n",
      "\n",
      "**Activity Title:** \"Rolling with Probability\"\n",
      "\n",
      "**Objective:** To introduce 8th graders to the concept of probability and its application in real-life situations through a hands-on activity.\n",
      "\n",
      "**Materials:**\n",
      "\n",
      "* A standard six-sided die (d6)\n",
      "* Whiteboard or chalkboard\n",
      "* Markers or chalk\n",
      "* Printed copies of the probability formula (P = number of favorable outcomes / total number of possible outcomes)\n",
      "\n",
      "**Step-by-Step Procedure:**\n",
      "\n",
      "1. Introduction (5 minutes):\n",
      "\t* Introduce the concept of probability and ask students if they have ever heard of it.\n",
      "\t* Write the definition on the board: \"Probability is a measure of how likely an event is to occur.\"\n",
      "2. Direct Instruction (10 minutes):\n",
      "\t* Explain that probability can be calculated using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "\t* Use simple examples, such as flipping a coin or rolling a die, to illustrate the concept.\n",
      "\t* Write the formula on the board and have students copy it onto their printed copies.\n",
      "3. Guided Practice (20 minutes):\n",
      "\t* Divide the class into small groups of 3-4 students.\n",
      "\t* Give each group a set of questions related to probability, such as:\n",
      "\t\t+ What is the probability of rolling an even number on a d6?\n",
      "\t\t+ What is the probability of drawing a heart from a standard deck of cards?\n",
      "\t* Have each group work together to calculate the probabilities using the formula.\n",
      "\t* Circulate around the room to assist and provide feedback.\n",
      "4. Independent Practice (15 minutes):\n",
      "\t* Provide students with a blank sheet of paper and ask them to design their own probability experiment, such as rolling different types of dice or drawing cards from a deck.\n",
      "\t* Encourage students to calculate the probabilities for their experiment using the formula.\n",
      "5. Conclusion (10 minutes):\n",
      "\t* Have each group present their findings and discuss any common misconceptions or misunderstandings.\n",
      "\t* Review the key concepts learned during the activity, including the probability formula and its application.\n",
      "\n",
      "**Expected Learning Outcomes:**\n",
      "\n",
      "* Students will be able to define probability and explain its relationship to chance events.\n",
      "* Students will be able to calculate probabilities using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "* Students will apply probability concepts to real-life situations, such as predicting the outcome of a coin toss or rolling different types of dice.\n",
      "\n",
      "**Assessment:**\n",
      "\n",
      "* Observe student participation during the activity and assess their understanding through group presentations.\n",
      "* Review student worksheets for accuracy and completeness.\n",
      "* Use a rubric to evaluate student experiments and provide feedback on their ability to apply probability concepts.\n",
      "\n",
      "Draft 2:\n",
      "**Activity Title:** \"Rolling with Probability\"\n",
      "\n",
      "**Objective:** To introduce 8th graders to the concept of probability and its application in real-life situations through a hands-on activity.\n",
      "\n",
      "**Materials:**\n",
      "\n",
      "* A standard six-sided die (d6)\n",
      "* Whiteboard or chalkboard\n",
      "* Markers or chalk\n",
      "* Printed copies of the probability formula (P = number of favorable outcomes / total number of possible outcomes)\n",
      "\n",
      "**Step-by-Step Procedure:**\n",
      "\n",
      "1. Introduction (5 minutes):\n",
      "\t* Introduce the concept of probability and ask students if they have ever heard of it.\n",
      "\t* Write the definition on the board: \"Probability is a measure of how likely an event is to occur.\"\n",
      "2. Direct Instruction (10 minutes):\n",
      "\t* Explain that probability can be calculated using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "\t* Use simple examples, such as flipping a coin or rolling a die, to illustrate the concept.\n",
      "\t* Write the formula on the board and have students copy it onto their printed copies.\n",
      "3. Guided Practice (20 minutes):\n",
      "\t* Divide the class into small groups of 3-4 students.\n",
      "\t* Give each group a set of questions related to probability, such as:\n",
      "\t\t+ What is the probability of rolling an even number on a d6?\n",
      "\t\t+ What is the probability of drawing a heart from a standard deck of cards?\n",
      "\t* Have each group work together to calculate the probabilities using the formula.\n",
      "\t* Circulate around the room to assist and provide feedback.\n",
      "4. Independent Practice (15 minutes):\n",
      "\t* Provide students with a blank sheet of paper and ask them to design their own probability experiment, such as rolling different types of dice or drawing cards from a deck.\n",
      "\t* Encourage students to calculate the probabilities for their experiment using the formula.\n",
      "5. Conclusion (10 minutes):\n",
      "\t* Have each group present their findings and discuss any common misconceptions or misunderstandings.\n",
      "\t* Review the key concepts learned during the activity, including the probability formula and its application.\n",
      "\n",
      "**Expected Learning Outcomes:**\n",
      "\n",
      "* Students will understand the concept of probability and its relationship to chance events.\n",
      "* Students will be able to calculate probabilities using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "* Students will apply probability concepts to real-life situations through a hands-on experiment.\n",
      "\n",
      "**Assessment:**\n",
      "\n",
      "* Observe student participation during the activity and assess their understanding through group presentations.\n",
      "* Review student worksheets for accuracy and completeness.\n",
      "* Use a rubric to evaluate student experiments and provide feedback.\n",
      "\n",
      "**Main Weaknesses:**\n",
      "The only weakness in this draft is that there is no clear evaluation of student learning outcomes. Adding more specific language in the expected learning outcomes section would make it clearer what students are expected to learn from the activity.\n",
      "\n",
      "**Revised Draft:**\n",
      "\n",
      "**Activity Title:** \"Rolling with Probability\"\n",
      "\n",
      "**Objective:** To introduce 8th graders to the concept of probability and its application in real-life situations through a hands-on activity.\n",
      "\n",
      "**Materials:**\n",
      "\n",
      "* A standard six-sided die (d6)\n",
      "* Whiteboard or chalkboard\n",
      "* Markers or chalk\n",
      "* Printed copies of the probability formula (P = number of favorable outcomes / total number of possible outcomes)\n",
      "\n",
      "**Step-by-Step Procedure:**\n",
      "\n",
      "1. Introduction (5 minutes):\n",
      "\t* Introduce the concept of probability and ask students if they have ever heard of it.\n",
      "\t* Write the definition on the board: \"Probability is a measure of how likely an event is to occur.\"\n",
      "2. Direct Instruction (10 minutes):\n",
      "\t* Explain that probability can be calculated using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "\t* Use simple examples, such as flipping a coin or rolling a die, to illustrate the concept.\n",
      "\t* Write the formula on the board and have students copy it onto their printed copies.\n",
      "3. Guided Practice (20 minutes):\n",
      "\t* Divide the class into small groups of 3-4 students.\n",
      "\t* Give each group a set of questions related to probability, such as:\n",
      "\t\t+ What is the probability of rolling an even number on a d6?\n",
      "\t\t+ What is the probability of drawing a heart from a standard deck of cards?\n",
      "\t* Have each group work together to calculate the probabilities using the formula.\n",
      "\t* Circulate around the room to assist and provide feedback.\n",
      "4. Independent Practice (15 minutes):\n",
      "\t* Provide students with a blank sheet of paper and ask them to design their own probability experiment, such as rolling different types of dice or drawing cards from a deck.\n",
      "\t* Encourage students to calculate the probabilities for their experiment using the formula.\n",
      "5. Conclusion (10 minutes):\n",
      "\t* Have each group present their findings and discuss any common misconceptions or misunderstandings.\n",
      "\t* Review the key concepts learned during the activity, including the probability formula and its application.\n",
      "\n",
      "**Expected Learning Outcomes:**\n",
      "\n",
      "* Students will be able to define probability and explain its relationship to chance events.\n",
      "* Students will be able to calculate probabilities using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "* Students will apply probability concepts to real-life situations, such as predicting the outcome of a coin toss or rolling different types of dice.\n",
      "\n",
      "**Assessment:**\n",
      "\n",
      "* Observe student participation during the activity and assess their understanding through group presentations.\n",
      "* Review student worksheets for accuracy and completeness.\n",
      "* Use a rubric to evaluate student experiments and provide feedback on their ability to apply probability concepts.\n",
      "\n",
      "Draft 3:\n",
      "**Activity Title:** \"Rolling with Probability\"\n",
      "\n",
      "**Objective:** To introduce 8th graders to the concept of probability and its application in real-life situations through a hands-on activity.\n",
      "\n",
      "**Materials:**\n",
      "\n",
      "* A standard six-sided die (d6)\n",
      "* Whiteboard or chalkboard\n",
      "* Markers or chalk\n",
      "* Printed copies of the probability formula (P = number of favorable outcomes / total number of possible outcomes)\n",
      "\n",
      "**Step-by-Step Procedure:**\n",
      "\n",
      "1. Introduction (5 minutes):\n",
      "\t* Introduce the concept of probability and ask students if they have ever heard of it.\n",
      "\t* Write the definition on the board: \"Probability is a measure of how likely an event is to occur.\"\n",
      "2. Direct Instruction (10 minutes):\n",
      "\t* Explain that probability can be calculated using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "\t* Use simple examples, such as flipping a coin or rolling a die, to illustrate the concept.\n",
      "\t* Write the formula on the board and have students copy it onto their printed copies.\n",
      "3. Guided Practice (20 minutes):\n",
      "\t* Divide the class into small groups of 3-4 students.\n",
      "\t* Give each group a set of questions related to probability, such as:\n",
      "\t\t+ What is the probability of rolling an even number on a d6?\n",
      "\t\t+ What is the probability of drawing a heart from a standard deck of cards?\n",
      "\t* Have each group work together to calculate the probabilities using the formula.\n",
      "\t* Circulate around the room to assist and provide feedback.\n",
      "4. Independent Practice (15 minutes):\n",
      "\t* Provide students with a blank sheet of paper and ask them to design their own probability experiment, such as rolling different types of dice or drawing cards from a deck.\n",
      "\t* Encourage students to calculate the probabilities for their experiment using the formula.\n",
      "5. Conclusion (10 minutes):\n",
      "\t* Have each group present their findings and discuss any common misconceptions or misunderstandings.\n",
      "\t* Review the key concepts learned during the activity, including the probability formula and its application.\n",
      "\n",
      "**Expected Learning Outcomes:**\n",
      "\n",
      "* Students will be able to define probability and explain its relationship to chance events.\n",
      "* Students will be able to calculate probabilities using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "* Students will apply probability concepts to real-life situations, such as predicting the outcome of a coin toss or rolling different types of dice.\n",
      "\n",
      "**Assessment:**\n",
      "\n",
      "* Observe student participation during the activity and assess their understanding through group presentations.\n",
      "* Review student worksheets for accuracy and completeness.\n",
      "* Use a rubric to evaluate student experiments and provide feedback on their ability to apply probability concepts.\n",
      "\n",
      "**Additional Support:**\n",
      "To further enhance student learning, consider providing additional resources such as online interactive simulations or real-world examples of probability in action.\n",
      "\n",
      "Final draft:\n",
      " **Activity Title:** \"Rolling with Probability\"\n",
      "\n",
      "**Objective:** To introduce 8th graders to the concept of probability and its application in real-life situations through a hands-on activity.\n",
      "\n",
      "**Materials:**\n",
      "\n",
      "* A standard six-sided die (d6)\n",
      "* Whiteboard or chalkboard\n",
      "* Markers or chalk\n",
      "* Printed copies of the probability formula (P = number of favorable outcomes / total number of possible outcomes)\n",
      "\n",
      "**Step-by-Step Procedure:**\n",
      "\n",
      "1. Introduction (5 minutes):\n",
      "\t* Introduce the concept of probability and ask students if they have ever heard of it.\n",
      "\t* Write the definition on the board: \"Probability is a measure of how likely an event is to occur.\"\n",
      "2. Direct Instruction (10 minutes):\n",
      "\t* Explain that probability can be calculated using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "\t* Use simple examples, such as flipping a coin or rolling a die, to illustrate the concept.\n",
      "\t* Write the formula on the board and have students copy it onto their printed copies.\n",
      "3. Guided Practice (20 minutes):\n",
      "\t* Divide the class into small groups of 3-4 students.\n",
      "\t* Give each group a set of questions related to probability, such as:\n",
      "\t\t+ What is the probability of rolling an even number on a d6?\n",
      "\t\t+ What is the probability of drawing a heart from a standard deck of cards?\n",
      "\t* Have each group work together to calculate the probabilities using the formula.\n",
      "\t* Circulate around the room to assist and provide feedback.\n",
      "4. Independent Practice (15 minutes):\n",
      "\t* Provide students with a blank sheet of paper and ask them to design their own probability experiment, such as rolling different types of dice or drawing cards from a deck.\n",
      "\t* Encourage students to calculate the probabilities for their experiment using the formula.\n",
      "5. Conclusion (10 minutes):\n",
      "\t* Have each group present their findings and discuss any common misconceptions or misunderstandings.\n",
      "\t* Review the key concepts learned during the activity, including the probability formula and its application.\n",
      "\n",
      "**Expected Learning Outcomes:**\n",
      "\n",
      "* Students will be able to define probability and explain its relationship to chance events.\n",
      "* Students will be able to calculate probabilities using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "* Students will apply probability concepts to real-life situations, such as predicting the outcome of a coin toss or rolling different types of dice.\n",
      "\n",
      "**Assessment:**\n",
      "\n",
      "* Observe student participation during the activity and assess their understanding through group presentations.\n",
      "* Review student worksheets for accuracy and completeness.\n",
      "* Use a rubric to evaluate student experiments and provide feedback on their ability to apply probability concepts.\n",
      "\n",
      "**Additional Support:**\n",
      "To further enhance student learning, consider providing additional resources such as online interactive simulations or real-world examples of probability in action.\n",
      "\n",
      "Draft 3:\n",
      "**Activity Title:** \"Rolling with Probability\"\n",
      "\n",
      "**Objective:** To introduce 8th graders to the concept of probability and its application in real-life situations through a hands-on activity.\n",
      "\n",
      "**Materials:**\n",
      "\n",
      "* A standard six-sided die (d6)\n",
      "* Whiteboard or chalkboard\n",
      "* Markers or chalk\n",
      "* Printed copies of the probability formula (P = number of favorable outcomes / total number of possible outcomes)\n",
      "\n",
      "**Step-by-Step Procedure:**\n",
      "\n",
      "1. Introduction (5 minutes):\n",
      "\t* Introduce the concept of probability and ask students if they have ever heard of it.\n",
      "\t* Write the definition on the board: \"Probability is a measure of how likely an event is to occur.\"\n",
      "2. Direct Instruction (10 minutes):\n",
      "\t* Explain that probability can be calculated using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "\t* Use simple examples, such as flipping a coin or rolling a die, to illustrate the concept.\n",
      "\t* Write the formula on the board and have students copy it onto their printed copies.\n",
      "3. Guided Practice (20 minutes):\n",
      "\t* Divide the class into small groups of 3-4 students.\n",
      "\t* Give each group a set of questions related to probability, such as:\n",
      "\t\t+ What is the probability of rolling an even number on a d6?\n",
      "\t\t+ What is the probability of drawing a heart from a standard deck of cards?\n",
      "\t* Have each group work together to calculate the probabilities using the formula.\n",
      "\t* Circulate around the room to assist and provide feedback.\n",
      "4. Independent Practice (15 minutes):\n",
      "\t* Provide students with a blank sheet of paper and ask them to design their own probability experiment, such as rolling different types of dice or drawing cards from a deck.\n",
      "\t* Encourage students to calculate the probabilities for their experiment using the formula.\n",
      "5. Conclusion (10 minutes):\n",
      "\t* Have each group present their findings and discuss any common misconceptions or misunderstandings.\n",
      "\t* Review the key concepts learned during the activity, including the probability formula and its application.\n",
      "\n",
      "**Expected Learning Outcomes:**\n",
      "\n",
      "* Students will be able to define probability and explain its relationship to chance events.\n",
      "* Students will be able to calculate probabilities using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "* Students will apply probability concepts to real-life situations, such as predicting the outcome of a coin toss or rolling different types of dice.\n",
      "\n",
      "**Assessment:**\n",
      "\n",
      "* Observe student participation during the activity and assess their understanding through group presentations.\n",
      "* Review student worksheets for accuracy and completeness.\n",
      "* Use a rubric to evaluate student experiments and provide feedback on their ability to apply probability concepts.\n",
      "\n",
      "**Additional Support:**\n",
      "To further enhance student learning, consider providing additional resources such as online interactive simulations or real-world examples of probability in action.\n",
      "\n",
      "Final draft:\n",
      " **Activity Title:** \"Rolling with Probability\"\n",
      "\n",
      "**Objective:** To introduce 8th graders to the concept of probability and its application in real-life situations through a hands-on activity.\n",
      "\n",
      "**Materials:**\n",
      "\n",
      "* A standard six-sided die (d6)\n",
      "* Whiteboard or chalkboard\n",
      "* Markers or chalk\n",
      "* Printed copies of the probability formula (P = number of favorable outcomes / total number of possible outcomes)\n",
      "\n",
      "**Step-by-Step Procedure:**\n",
      "\n",
      "1. Introduction (5 minutes):\n",
      "\t* Introduce the concept of probability and ask students if they have ever heard of it.\n",
      "\t* Write the definition on the board: \"Probability is a measure of how likely an event is to occur.\"\n",
      "2. Direct Instruction (10 minutes):\n",
      "\t* Explain that probability can be calculated using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "\t* Use simple examples, such as flipping a coin or rolling a die, to illustrate the concept.\n",
      "\t* Write the formula on the board and have students copy it onto their printed copies.\n",
      "3. Guided Practice (20 minutes):\n",
      "\t* Divide the class into small groups of 3-4 students.\n",
      "\t* Give each group a set of questions related to probability, such as:\n",
      "\t\t+ What is the probability of rolling an even number on a d6?\n",
      "\t\t+ What is the probability of drawing a heart from a standard deck of cards?\n",
      "\t* Have each group work together to calculate the probabilities using the formula.\n",
      "\t* Circulate around the room to assist and provide feedback.\n",
      "4. Independent Practice (15 minutes):\n",
      "\t* Provide students with a blank sheet of paper and ask them to design their own probability experiment, such as rolling different types of dice or drawing cards from a deck.\n",
      "\t* Encourage students to calculate the probabilities for their experiment using the formula.\n",
      "5. Conclusion (10 minutes):\n",
      "\t* Have each group present their findings and discuss any common misconceptions or misunderstandings.\n",
      "\t* Review the key concepts learned during the activity, including the probability formula and its application.\n",
      "\n",
      "**Expected Learning Outcomes:**\n",
      "\n",
      "* Students will be able to define probability and explain its relationship to chance events.\n",
      "* Students will be able to calculate probabilities using the formula P = number of favorable outcomes / total number of possible outcomes.\n",
      "* Students will apply probability concepts to real-life situations, such as predicting the outcome of a coin toss or rolling different types of dice.\n",
      "\n",
      "**Assessment:**\n",
      "\n",
      "* Observe student participation during the activity and assess their understanding through group presentations.\n",
      "* Review student worksheets for accuracy and completeness.\n",
      "* Use a rubric to evaluate student experiments and provide feedback on their ability to apply probability concepts.\n",
      "\n",
      "**Additional Support:**\n",
      "To further enhance student learning, consider providing additional resources such as online interactive simulations or real-world examples of probability in action.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def sequential_revision(question: str, max_steps: int = 3) -> str:\n",
    "    \"\"\"Generate an initial draft answer then iteratively refine it.\n",
    "\n",
    "    Workflow:\n",
    "    - Produce a first draft that includes step-by-step reasoning and a short final answer.\n",
    "    - For up to `max_steps-1` revision rounds, ask the model to (1) briefly critique the previous draft and (2) produce an improved revision.\n",
    "    - Stop early if the model returns the same draft (no changes).\n",
    "\n",
    "    Returns the final draft string. Prints each draft so you can observe evolution.\n",
    "    \"\"\"\n",
    "    # Build initial prompt for a first draft\n",
    "    init_prompt = f\"\"\"You are an experienced instructor. Produce a concise draft answer to the question below that includes step-by-step reasoning and a brief final answer.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Draft:\"\"\"\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": init_prompt}],\n",
    "            temperature=0.5,\n",
    "        )\n",
    "        draft = resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"<ERROR generating initial draft: {e}>\"\n",
    "\n",
    "    print(\"Draft 1:\\n\", draft)\n",
    "\n",
    "    # Iteratively refine\n",
    "    for step in range(2, max_steps + 1):\n",
    "        revise_prompt = f\"\"\"You are a concise editor and domain expert. Here is the previous draft answer:\n",
    "\n",
    "{draft}\n",
    "\n",
    "1) In 1-2 short sentences, list the main weaknesses or inaccuracies (if any).\n",
    "2) Produce a revised improved draft that addresses those weaknesses. Keep the style clear and the final answer concise. Output only the revised draft.\n",
    "\n",
    "Revised draft:\"\"\"\n",
    "        try:\n",
    "            r = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": revise_prompt}],\n",
    "                temperature=0.6,\n",
    "            )\n",
    "            new_draft = r.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"<ERROR during revision step {step}: {e}>\")\n",
    "            break\n",
    "\n",
    "        # If model returns same content, stop early\n",
    "        if new_draft == draft:\n",
    "            print(f\"\\nNo substantive change at step {step}; stopping early.\")\n",
    "            break\n",
    "\n",
    "        draft = new_draft\n",
    "        print(f\"\\nDraft {step}:\\n{draft}\")\n",
    "\n",
    "    return draft\n",
    "\n",
    "\n",
    "# Example usage (not wrapped in __main__ so it's visible in the notebook execution output)\n",
    "question = (\n",
    "    \"Design a 1-hour hands-on activity to teach 8th graders the basics of probability. \"\n",
    "    \"Include required materials, step-by-step procedures, and expected learning outcomes.\"\n",
    ")\n",
    "final = sequential_revision(question, max_steps=3)\n",
    "print(\"\\nFinal draft:\\n\", final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9319ee8",
   "metadata": {},
   "source": [
    "### 2.5 Tree‑of‑Thoughts\n",
    "Tree-of-Thoughts reframes reasoning as a search process rather than a single forward chain.\n",
    "Instead of producing one linear sequence of thoughts, the model generates multiple candidate thoughts at each step, evaluates their promise, and then expands only the best few. This allows exploration of different reasoning paths before committing to a final answer, similar to how humans brainstorm, prune, and refine ideas.\n",
    "\n",
    "\n",
    "In this section, you’ll experiment with two simplified versions of ToT:\n",
    "1. Word Ladder puzzle solver: a small example where each “thought” is a candidate word transition.\n",
    "2. Generic ToT search (depth 2, width 2): a minimal logic to expand, evaluate, and select reasoning branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d047801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hit', 'hot', 'dot', 'dog', 'cog']\n"
     ]
    }
   ],
   "source": [
    "###### Word Ladder Puzzle ##########\n",
    "\n",
    "def neighbors(word, vocabulary):\n",
    "    # Generate all valid one-letter mutations of 'word' that exist in 'vocabulary' and return them.\n",
    "    \"\"\"\n",
    "    For each position in `word`, replace with letters a-z and check membership in `vocabulary`.\n",
    "    Returns a sorted list for deterministic behavior.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    word = word.lower()\n",
    "    for i in range(len(word)):\n",
    "        for c in alphabet:\n",
    "            if c == word[i]:\n",
    "                continue\n",
    "            candidate = word[:i] + c + word[i+1:]\n",
    "            if candidate in vocabulary:\n",
    "                res.append(candidate)\n",
    "    return sorted(set(res))\n",
    "\n",
    "\n",
    "def _hamming_distance(a: str, b: str) -> int:\n",
    "    # Simple distance assuming equal length words (suitable for classic word-ladder puzzles)\n",
    "    if len(a) != len(b):\n",
    "        # Fall back to a simple edit distance if lengths differ\n",
    "        # (basic Levenshtein dynamic programming)\n",
    "        n, m = len(a), len(b)\n",
    "        dp = [[0]*(m+1) for _ in range(n+1)]\n",
    "        for i in range(n+1):\n",
    "            dp[i][0] = i\n",
    "        for j in range(m+1):\n",
    "            dp[0][j] = j\n",
    "        for i in range(1, n+1):\n",
    "            for j in range(1, m+1):\n",
    "                cost = 0 if a[i-1]==b[j-1] else 1\n",
    "                dp[i][j] = min(dp[i-1][j]+1, dp[i][j-1]+1, dp[i-1][j-1]+cost)\n",
    "        return dp[n][m]\n",
    "    # Hamming distance\n",
    "    return sum(1 for x, y in zip(a, b) if x != y)\n",
    "\n",
    "\n",
    "def tree_of_thought(start, goal, vocab, max_depth=5, beam_width=4):\n",
    "    \"\"\"Search over partial thoughts (paths) using a small beam.\n",
    "\n",
    "    Algorithm (beam search):\n",
    "      - frontier: list of paths (each path is a list of words)\n",
    "      - expand each path by neighbors of its last word (skip words already in path)\n",
    "      - score paths by distance(last_word, goal) (smaller is better)\n",
    "      - keep top `beam_width` paths at each depth\n",
    "      - if any path reaches goal, return that path\n",
    "\n",
    "    Returns: a list of words forming a path from start to goal, or None if not found.\n",
    "    \"\"\"\n",
    "    start, goal = start.lower(), goal.lower()\n",
    "    if start == goal:\n",
    "        return [start]\n",
    "\n",
    "    # quick checks\n",
    "    if start not in vocab or goal not in vocab:\n",
    "        # allow solution even if start/goal not in vocab by treating vocab as additional allowed words\n",
    "        pass\n",
    "\n",
    "    frontier = [[start]]\n",
    "    for depth in range(1, max_depth+1):\n",
    "        candidates = []\n",
    "        for path in frontier:\n",
    "            last = path[-1]\n",
    "            for nb in neighbors(last, vocab):\n",
    "                if nb in path:\n",
    "                    continue  # avoid cycles\n",
    "                new_path = path + [nb]\n",
    "                # if reached goal, return immediately\n",
    "                if nb == goal:\n",
    "                    return new_path\n",
    "                # score by distance between last node and goal\n",
    "                score = _hamming_distance(nb, goal)\n",
    "                candidates.append((score, new_path))\n",
    "        if not candidates:\n",
    "            # no expansions possible\n",
    "            break\n",
    "        # sort by score (lower is better) then by path length to stabilize\n",
    "        candidates.sort(key=lambda x: (x[0], len(x[1])))\n",
    "        # keep top beam_width paths\n",
    "        frontier = [p for (_, p) in candidates[:beam_width]]\n",
    "    # If no path hit the goal, return the best path (closest to goal) found or None\n",
    "    if frontier:\n",
    "        # pick the path whose last node is nearest to goal\n",
    "        best = min(frontier, key=lambda p: _hamming_distance(p[-1], goal))\n",
    "        return best\n",
    "    return None\n",
    "\n",
    "\n",
    "vocab = {\"hit\",\"dot\",\"cog\",\"log\",\"dog\",\"lot\",\"lit\",\"hot\"}\n",
    "print(tree_of_thought(\"hit\", \"cog\", vocab)) # one candidate solution: ['hit', 'hot', 'dot', 'dog', 'cog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89067302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution (score 6):\n",
      "Invite experienced STEM teachers \n",
      "Collaborate with local schools\n"
     ]
    }
   ],
   "source": [
    "###### Generic ToT Search ##########\n",
    "\n",
    "import re\n",
    "\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "\n",
    "def propose_thoughts(question, state, k=2, temperature=0.8):\n",
    "    \"\"\"Propose up to k next \"thoughts\" extending `state` for `question`.\n",
    "\n",
    "    Returns a list of up to k short strings (no numbering, trimmed).\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a helpful assistant that proposes short next-step \"thoughts\" for solving a problem.\n",
    "Problem: {question}\n",
    "\n",
    "Current partial solution / state:\n",
    "{state}\n",
    "\n",
    "Propose up to {k} concise next steps or ideas (1-6 words each). Return them as a newline-separated list without extra explanation.\n",
    "\"\"\"\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        out = resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        # On error, return empty list so search can continue gracefully\n",
    "        print(f\"propose_thoughts error: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Parse lines, remove numbering/bullets and empty lines\n",
    "    lines = []\n",
    "    for raw in out.splitlines():\n",
    "        s = raw.strip()\n",
    "        # remove leading numbering or bullets like '1. ', '- ', '* '\n",
    "        s = re.sub(r'^\\s*\\d+\\.\\s*', '', s)\n",
    "        s = re.sub(r'^\\s*[-*]\\s*', '', s)\n",
    "        if s:\n",
    "            lines.append(s)\n",
    "        if len(lines) >= k:\n",
    "            break\n",
    "    return lines\n",
    "\n",
    "\n",
    "def score_state(question, state, temperature=0.0):\n",
    "    \"\"\"Score a partial `state` from 1..10 on how promising it is for solving `question`.\n",
    "\n",
    "    Returns an integer score (1..10). On failure returns 0.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a strict evaluator. Given the problem and a partial plan, rate how promising the partial plan is to lead to a correct and complete solution.\n",
    "\n",
    "Problem: {question}\n",
    "Partial solution / state:\n",
    "{state}\n",
    "\n",
    "On a scale from 1 to 10 (1 = not promising, 10 = very promising), give ONLY the integer score as your answer.\n",
    "\"\"\"\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        out = resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"score_state error: {e}\")\n",
    "        return 0\n",
    "\n",
    "    # extract first integer 1-10\n",
    "    m = re.search(r\"\\b([1-9]|10)\\b\", out)\n",
    "    if m:\n",
    "        try:\n",
    "            return int(m.group(1))\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    # fallback: try to parse any leading number\n",
    "    m2 = re.search(r\"(-?\\d+)\", out)\n",
    "    if m2:\n",
    "        v = int(m2.group(1))\n",
    "        return max(0, min(10, v))\n",
    "    return 0\n",
    "\n",
    "\n",
    "def tree_of_thoughts(question, depth=2, width=2):\n",
    "    \"\"\"Run a tiny Tree-of-Thoughts search.\n",
    "\n",
    "    Returns (best_state_string, best_score).\n",
    "    - Initialize frontier with an empty state \"\".\n",
    "    - For each depth, expand each state by k=width proposed thoughts.\n",
    "    - Score expanded states and keep top `width` (by score desc).\n",
    "    - At the end, return the top state's string and score.\n",
    "    \"\"\"\n",
    "    frontier = [(\"\", 0)]  # list of (state_string, score)\n",
    "\n",
    "    for d in range(depth):\n",
    "        expanded = []\n",
    "        for state, _ in frontier:\n",
    "            proposals = propose_thoughts(question, state, k=width)\n",
    "            if not proposals:\n",
    "                continue\n",
    "            for p in proposals:\n",
    "                new_state = (state + \" \\n\" + p).strip()\n",
    "                sc = score_state(question, new_state)\n",
    "                expanded.append((new_state, sc))\n",
    "        if not expanded:\n",
    "            break\n",
    "        # sort by score desc, then shorter states (tie-break)\n",
    "        expanded.sort(key=lambda x: (-x[1], len(x[0])))\n",
    "        frontier = expanded[:width]\n",
    "\n",
    "    # choose best in frontier\n",
    "    if frontier:\n",
    "        best_state, best_score = frontier[0]\n",
    "        return best_state, best_score\n",
    "    return \"\", 0\n",
    "\n",
    "\n",
    "# Demo run\n",
    "question = \"Design a plan for a weekend science workshop for 12-year-olds.\"\n",
    "solution, score = tree_of_thoughts(question, depth=2, width=2)\n",
    "print(f\"Best solution (score {score}):\\n{solution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc38f6",
   "metadata": {},
   "source": [
    "---  \n",
    "# 3‑ Training Models for Reasoning\n",
    "\n",
    "### 3.1: CoT Training\n",
    "Chain-of-Thought (CoT) training conditions the model on explicit rationales during fine-tuning. Instead of teaching the model to output only the final answer, we train on (question, rationale, answer) so the model learns to internalize multi-step reasoning patterns. A practical recipe is STaR (Self-Taught Reasoner), which uses a stronger teacher model to bootstrap rationales that a smaller student can learn from.\n",
    "\n",
    "For tasks that require multi-hop reasoning, models fine-tuned on rationales often achieve higher accuracy and are more stable at inference time than models trained on direct answers only. \n",
    "\n",
    "Training a full language model is beyond the scope of this notebook, but here is the high-level workflow followed by a short pseudocode:\n",
    "- Collect questions: Prepare a dataset of questions and correct answers.\n",
    "- Generate rationales: Use a strong LLM to produce step-by-step reasoning ending with the correct answer.\n",
    "- Filter and clean: Discard incorrect or low-quality rationales.\n",
    "- Prepare training data: Format triples (question, rationale, answer) for supervised fine-tuning.\n",
    "- Fine-tune: Fine-tune the LLM on rationales.\n",
    "- Iterate: Refine prompts, improve data quality, and retrain for stronger reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode (STaR loop)\n",
    "# for round in 1 ... iters:\n",
    "    # STEP 1: self-generate reasoning (teacher creates rationale + answer)\n",
    "    # STEP 2: keep only correct, high-quality traces\n",
    "    # STEP 3: fine-tune student on (question, rationale, answer) data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b53c70",
   "metadata": {},
   "source": [
    "### 3.2: ORM vs PRM + RL\n",
    "Training a Reward Model (RM) allows large language models to be improved through reinforcement learning (RL). Instead of fine-tuning directly on examples, we train a separate model that can score or rank model outputs, and use those scores as feedback signals to refine the policy model.\n",
    "\n",
    "Two main reward modeling approaches are ORM (predicts a scalar reward for the final answer) and PRM (evaluates the reasoning steps instead of just the outcome)\n",
    "\n",
    "\n",
    "\n",
    "| Approach | Typical loss | When to use |\n",
    "|-----------|-------------|-------------|\n",
    "|*Outcome Reward Model* | Predict scalar reward | Easy to collect training data using verifiers |\n",
    "|*Process Reward Model* | Predict rewards per step | Difficult to collect training data but more accurate |\n",
    "| *RLHF* | Use RM as reward in **RL** fine‑tuning | Aligns policy with human signals | Aligns model policy with human or synthetic preferences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595635aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for round = 1 ... iters:\n",
    "    # STEP 1:  Generate reasoning\n",
    "        # sample a minibatch of questions\n",
    "        # policy roll‑out (actions + log‑probs)\n",
    "    # STEP 2:  Score the trajectory\n",
    "        # ORM: scalar reward for the final answer / PRM: scalar reward for the thought process\n",
    "    # STEP 3:  Reinforce the policy (PPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a81a6",
   "metadata": {},
   "source": [
    "---  \n",
    "# 4‑ A Deep Research Agent\n",
    "\n",
    "A deep-research agent pairs a reasoning model (e.g., deepseek-r1) with external tools for web search and retrieval. We will follow the ReAct pattern: the model writes short thoughts, decides when to call tools, reads observations, and continues reasoning until it can answer or reaches a step limit.\n",
    "\n",
    "We now combine a **search tool** with a reasoning model (e.g., `deepseek-r1`) in a multi-step setup. We follow the *ReAct* pattern (reason → tool → observation):\n",
    "\n",
    "1. The model reasoins and decides to use tools\n",
    "2. The agent searches and feed condensed snippets back as context\n",
    "3. Iterate until the model answers or hits a step limit\n",
    "\n",
    "We use `AgentType.OPENAI_FUNCTIONS`, which hides the loop inside the LangChain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd1e1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs import DDGS\n",
    "from langchain.tools import Tool\n",
    "\n",
    "def ddg_search(query: str, k: int = 5) -> str:\n",
    "    # Use DDGS to run a simple web search and return joined snippets.\n",
    "    \"\"\"\n",
    "    Perform a DuckDuckGo search and return the top-k short snippets concatenated.\n",
    "    \"\"\"\n",
    "    snippets = []\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            for i, res in enumerate(ddgs.search(query, timelimit='y')):\n",
    "                if i >= k:\n",
    "                    break\n",
    "                title = res.get('title') or ''\n",
    "                excerpt = res.get('excerpt') or res.get('body') or res.get('text') or ''\n",
    "                link = res.get('href') or res.get('link') or ''\n",
    "                piece = ' - '.join([p for p in (title.strip(), excerpt.strip()) if p])\n",
    "                if not piece:\n",
    "                    piece = link\n",
    "                snippets.append(piece)\n",
    "    except Exception as e:\n",
    "        return f\"<DDG_ERROR: {e}>\"\n",
    "\n",
    "    return \"\\n\\n\".join(snippets)\n",
    "\n",
    "# Register the search tool for the agent\n",
    "search_tool = Tool(\n",
    "    name=\"DuckDuckGo Search\",\n",
    "    func=ddg_search,\n",
    "    description=\"Search the public web. Input: a plain English query. Returns: concatenated snippets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "418a0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vraje\\AppData\\Local\\Temp\\ipykernel_30924\\2340626039.py:9: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  chat = ChatOllama(model=MODEL)\n",
      "C:\\Users\\vraje\\AppData\\Local\\Temp\\ipykernel_30924\\2340626039.py:13: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent([search_tool], chat, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)\n",
      "C:\\Users\\vraje\\AppData\\Local\\Temp\\ipykernel_30924\\2340626039.py:18: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = agent.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     13\u001b[39m agent = initialize_agent([search_tool], chat, agent=AgentType.OPENAI_FUNCTIONS, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Step 3: Ask a query and let the agent search + reason to produce an answer\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Run the agent on the question and print the result\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m answer = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAgent answer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, answer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:193\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    192\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain\\chains\\base.py:603\u001b[39m, in \u001b[36mChain.run\u001b[39m\u001b[34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[39m\n\u001b[32m    601\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) != \u001b[32m1\u001b[39m:\n\u001b[32m    602\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`run` supports only one positional argument.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[32m    604\u001b[39m         _output_key\n\u001b[32m    605\u001b[39m     ]\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[32m    609\u001b[39m         _output_key\n\u001b[32m    610\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:193\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    192\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain\\chains\\base.py:386\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    355\u001b[39m \n\u001b[32m    356\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    377\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    379\u001b[39m config = {\n\u001b[32m    380\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    381\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    382\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    383\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    384\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain\\chains\\base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    166\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    168\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain\\chains\\base.py:157\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    156\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    163\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain\\agents\\agent.py:1620\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1618\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1627\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1628\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1629\u001b[39m             next_step_output, intermediate_steps, run_manager=run_manager\n\u001b[32m   1630\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain\\agents\\agent.py:1326\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1318\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1319\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1323\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1324\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1326\u001b[39m         \u001b[43m[\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1336\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain\\agents\\agent.py:1326\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1318\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1319\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1323\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1324\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1326\u001b[39m         \u001b[43m[\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1336\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain\\agents\\agent.py:1354\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1351\u001b[39m     intermediate_steps = \u001b[38;5;28mself\u001b[39m._prepare_intermediate_steps(intermediate_steps)\n\u001b[32m   1353\u001b[39m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1354\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_action_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain\\agents\\openai_functions_agent\\base.py:124\u001b[39m, in \u001b[36mOpenAIFunctionsAgent.plan\u001b[39m\u001b[34m(self, intermediate_steps, callbacks, with_functions, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m messages = prompt.to_messages()\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m with_functions:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     predicted_message = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_messages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    130\u001b[39m     predicted_message = \u001b[38;5;28mself\u001b[39m.llm.predict_messages(\n\u001b[32m    131\u001b[39m         messages,\n\u001b[32m    132\u001b[39m         callbacks=callbacks,\n\u001b[32m    133\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:193\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    192\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1398\u001b[39m, in \u001b[36mBaseChatModel.predict_messages\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m   1388\u001b[39m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m0.1.7\u001b[39m\u001b[33m\"\u001b[39m, alternative=\u001b[33m\"\u001b[39m\u001b[33minvoke\u001b[39m\u001b[33m\"\u001b[39m, removal=\u001b[33m\"\u001b[39m\u001b[33m1.0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1389\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_messages\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1395\u001b[39m     **kwargs: Any,\n\u001b[32m   1396\u001b[39m ) -> BaseMessage:\n\u001b[32m   1397\u001b[39m     stop_ = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(stop)\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:193\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    192\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1317\u001b[39m, in \u001b[36mBaseChatModel.__call__\u001b[39m\u001b[34m(self, messages, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1291\u001b[39m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m0.1.7\u001b[39m\u001b[33m\"\u001b[39m, alternative=\u001b[33m\"\u001b[39m\u001b[33minvoke\u001b[39m\u001b[33m\"\u001b[39m, removal=\u001b[33m\"\u001b[39m\u001b[33m1.0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m   1293\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1297\u001b[39m     **kwargs: Any,\n\u001b[32m   1298\u001b[39m ) -> BaseMessage:\n\u001b[32m   1299\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model.\u001b[39;00m\n\u001b[32m   1300\u001b[39m \n\u001b[32m   1301\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1315\u001b[39m \n\u001b[32m   1316\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1317\u001b[39m     generation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1319\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m   1320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[32m   1321\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation.message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:842\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    840\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    841\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m         )\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    850\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1091\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1089\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1095\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:291\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    268\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    269\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    272\u001b[39m     **kwargs: Any,\n\u001b[32m    273\u001b[39m ) -> ChatResult:\n\u001b[32m    274\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[32m    275\u001b[39m \n\u001b[32m    276\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    288\u001b[39m \u001b[33;03m            ])\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m    299\u001b[39m         message=AIMessage(content=final_chunk.text),\n\u001b[32m    300\u001b[39m         generation_info=final_chunk.generation_info,\n\u001b[32m    301\u001b[39m     )\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations=[chat_generation])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:222\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    214\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    215\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m     **kwargs: Any,\n\u001b[32m    220\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    221\u001b[39m     final_chunk: Optional[ChatGenerationChunk] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chat_stream_response_to_chat_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:194\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_chat_stream\u001b[39m(\n\u001b[32m    185\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    186\u001b[39m     messages: List[BaseMessage],\n\u001b[32m    187\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    188\u001b[39m     **kwargs: Any,\n\u001b[32m    189\u001b[39m ) -> Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    190\u001b[39m     payload = {\n\u001b[32m    191\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._convert_messages_to_ollama_messages(messages),\n\u001b[32m    193\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_stream(\n\u001b[32m    195\u001b[39m         payload=payload, stop=stop, api_url=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.base_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/api/chat\u001b[39m\u001b[33m\"\u001b[39m, **kwargs\n\u001b[32m    196\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\requests\\models.py:869\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self, chunk_size, decode_unicode, delimiter)\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[32m    861\u001b[39m \u001b[33;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[32m    862\u001b[39m \u001b[33;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[32m    863\u001b[39m \n\u001b[32m    864\u001b[39m \u001b[33;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[32m    865\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    867\u001b[39m pending = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_unicode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_unicode\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\requests\\utils.py:562\u001b[39m, in \u001b[36mstream_decode_response_unicode\u001b[39m\u001b[34m(iterator, r)\u001b[39m\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    561\u001b[39m decoder = codecs.getincrementaldecoder(r.encoding)(errors=\u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrv\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrv\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\urllib3\\response.py:1088\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1086\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\urllib3\\response.py:1248\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1245\u001b[39m     amt = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1247\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1248\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left == \u001b[32m0\u001b[39m:\n\u001b[32m   1250\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\urllib3\\response.py:1167\u001b[39m, in \u001b[36mHTTPResponse._update_chunk_length\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m line = \u001b[38;5;28mself\u001b[39m._fp.fp.readline()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1168\u001b[39m line = line.split(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vraje\\miniconda3\\envs\\deep_research\\Lib\\socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "MODEL = \"deepseek-r1:8b\"\n",
    "question = \"What are the best resources to learn machine learning in 2025?\"\n",
    "\n",
    "# Step 1: Initialize the reasoning model via ChatOllama\n",
    "# Initialize the ChatOllama wrapper for the reasoning model\n",
    "chat = ChatOllama(model=MODEL)\n",
    "\n",
    "# Step 2: Build the agent with tool access (DuckDuckGo Search) and function-calling interface (initialize_agent)\n",
    "# Create the agent executor (ReAct-style) with function-calling support\n",
    "agent = initialize_agent([search_tool], chat, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)\n",
    "\n",
    "\n",
    "# Step 3: Ask a query and let the agent search + reason to produce an answer\n",
    "# Run the agent on the question and print the result\n",
    "answer = agent.run(question)\n",
    "print(\"Agent answer:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1c3f7",
   "metadata": {},
   "source": [
    "# Optional (Multi-agent Deep Research)\n",
    "Instead of a single multi-step agent, you can design multiple collaborating agents such as a Planner, Searcher, Summarizer, and Verifier that pass information and refine each other’s outputs. This setup improves robustness, diversity of reasoning, and division of labor.\n",
    "\n",
    "Try building a simple setup with 2–3 agents that share goals and messages, for example Planner → Researcher → Writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59abf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def parallel_research(query, n=3):\n",
    "    # Run n independent research runs in parallel and return their answers.\n",
    "    # Steps: use ThreadPoolExecutor; submit n calls to your agent/search pipeline; gather results in order.\n",
    "    \"\"\"\n",
    "    Runs n runs in parallel; if `agent` is available uses it, otherwise fallback to ddg_search.\n",
    "    \"\"\"\n",
    "    from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "    answers = []\n",
    "    def run_once(q):\n",
    "        try:\n",
    "            return agent.run(q)\n",
    "        except NameError:\n",
    "            return ddg_search(q, k=5)\n",
    "        except Exception as e:\n",
    "            return f\"<ERROR during run: {e}>\"\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=min(n, 8)) as ex:\n",
    "        futures = [ex.submit(run_once, query) for _ in range(n)]\n",
    "        for f in futures:\n",
    "            try:\n",
    "                answers.append(f.result(timeout=60))\n",
    "            except Exception as e:\n",
    "                answers.append(f\"<ERROR: {e}>\")\n",
    "\n",
    "    return answers\n",
    "\n",
    "answers = parallel_research(\"What are the best resources to learn ML in 2025?\", n=3)\n",
    "for i,a in enumerate(answers,1):\n",
    "    print(f\"[Run {i}] {a[:200]}…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507d0a4",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "* Practised various inference‑time reasoning methods\n",
    "* Gained intuition about training reasoning models\n",
    "* You have built a **deep-research agent**: reasoning model like deep-seek r1 + ReAct-style agent + tool use (web search)\n",
    "* Try adding more tools, and extending the deep-research to a multi-agent system: many agents researching web in parallel.\n",
    "\n",
    "\n",
    "👏 **Great job!** Take a moment to celebrate. The techniques you implemented here power many production agents and chatbots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f7fe8ac",
   "metadata": {},
   "source": [
    "# Project 3: **Ask‑the‑Web Agent**\n",
    "\n",
    "Welcome to Project 3! In this project, you will learn how to use tool‑calling LLMs, extend them with custom tools, and build a simplified *Perplexity‑style* agent that answers questions by searching the web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4311a6",
   "metadata": {},
   "source": [
    "## Learning Objectives  \n",
    "* Understand why tool calling is useful and how LLMs can invoke external tools.\n",
    "* Implement a minimal loop that parses the LLM's output and executes a Python function.\n",
    "* See how *function schemas* (docstrings and type hints) let us scale to many tools.\n",
    "* Use **LangChain** to get function‑calling capability for free (ReAct reasoning, memory, multi‑step planning).\n",
    "* Combine LLM with a web‑search tool to build a simple ask‑the‑web agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f16864",
   "metadata": {},
   "source": [
    "## Roadmap\n",
    "1. Environment setup\n",
    "2. Write simple tools and connect them to an LLM\n",
    "3. Standardize tool calling by writing `to_schema`\n",
    "4. Use LangChain to augment an LLM with your tools\n",
    "5. Build a Perplexity‑style web‑search agent\n",
    "6. (Optional) A minimal backend and frontend UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeae51d0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "# 1- Environment setup\n",
    "\n",
    "## 1.1- Conda environment\n",
    "\n",
    "Before we start coding, you need a reproducible setup. Open a terminal in the same directory as this notebook and run:\n",
    "\n",
    "```bash\n",
    "# Create and activate the conda environment\n",
    "conda env create -f environment.yml && conda activate web_agent\n",
    "\n",
    "# Register this environment as a Jupyter kernel\n",
    "python -m ipykernel install --user --name=web_agent --display-name \"web_agent\"\n",
    "```\n",
    "Once this is done, you can select “web_agent” from the Kernel → Change Kernel menu in Jupyter or VS Code.\n",
    "\n",
    "\n",
    "> Behind the scenes:\n",
    "> * Conda reads `environment.yml`, resolves the pinned dependencies, creates an isolated environment named `web_agent`, and activates it.\n",
    "> * `ollama pull` downloads the model so you can run it locally without API calls.\n",
    "\n",
    "\n",
    "## 1.2 Ollama setup\n",
    "\n",
    "In this project, we start with `gemma3-1B` because it is lightweight and runs on most machines. You can try other smaller or larger LLMs such as `mistral:7b`, `phi3:mini`, or `llama3.2:1b` to compare performance. Explore available models here: https://ollama.com/library\n",
    "\n",
    "```bash\n",
    "ollama pull gemma3:1b\n",
    "```\n",
    "\n",
    "`ollama pull` downloads the model so you can run it locally without API calls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c27158f",
   "metadata": {},
   "source": [
    "## 2- Tool Calling\n",
    "\n",
    "LLMs are strong at answering questions, but they cannot directly access external data such as live web results, APIs, or computations. In real applications, agents rarely rely only on their internal knowledge. They need to query APIs, retrieve data, or perform calculations to stay accurate and useful. Tool calling bridges this gap by allowing the LLM to request actions from the outside world.\n",
    "\n",
    "\n",
    "We describe each tool’s interface in the model’s prompt, defining what it does and what arguments it expects. When the model decides that a tool is needed, it emits a structured output like: `TOOL_CALL: {\"name\": \"get_current_weather\", \"args\": {\"city\": \"San Francisco\"}}`. Your code will detect this output, execute the corresponding function, and feed the result back to the LLM so the conversation continues.\n",
    "\n",
    "In this section, you will implement a simple `get_current_weather` function and teach the `gemma3` model how to use it when required in four steps:\n",
    "1. Implement the tool\n",
    "2. Create the instructions for the LLM\n",
    "3. Call the LLM with the prompt\n",
    "4. Parse the LLM output and call the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b5eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a536f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 1: Implement the tool\n",
    "# ---------------------------------------------------------\n",
    "# Your goal: give the model a way to access weather information.\n",
    "# You can either:\n",
    "#   (a) Call a real weather API (for example, OpenWeatherMap), or\n",
    "#   (b) Create a dummy function that returns a fixed response (e.g., \"It is 23°C and sunny in San Francisco.\")\n",
    "#\n",
    "# Requirements:\n",
    "#   • The function should be named `get_current_weather`\n",
    "#   • It should take two arguments:\n",
    "#         - city: str\n",
    "#         - unit: str = \"celsius\"\n",
    "#   • Return a short, human-readable sentence describing the weather.\n",
    "#\n",
    "# Example expected behavior:\n",
    "#   get_current_weather(\"San Francisco\") → \"It is 23°C and sunny in San Francisco.\"\n",
    "#\n",
    "\n",
    "def get_current_weather(city: str, unit: str = \"celsius\") -> str:\n",
    "    \"\"\"Return a short, human-readable weather sentence for `city`.\"\"\"\n",
    "    # Deterministic stub: map unit to symbol and return a fixed message\n",
    "    symbol = '°C' if unit.lower().startswith('c') else '°F'\n",
    "    # Use a fixed temperature for demonstration; real API calls can replace this\n",
    "    temp = 37 if symbol == '°C' else 73\n",
    "    return f\"It is {temp}{symbol} and sunny in {city}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a43c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 2: Create the prompt for the LLM to call tools\n",
    "# ---------------------------------------------------------\n",
    "# Goal:\n",
    "#   Build the system and user prompts that instruct the model when and how\n",
    "#   to use your tool (`get_current_weather`).\n",
    "#\n",
    "# What to include:\n",
    "#   • A SYSTEM_PROMPT that tells the model about the tool use and describe the tool\n",
    "#   • A USER_QUESTION with a user query that should trigger the tool.\n",
    "#       Example: \"What is the weather in San Diego today?\"\n",
    "\n",
    "# Try experimenting with different system and user prompts\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an AI assistant that helps users with weather information. \n",
    "You have access to a tool called `get_current_weather` that provides current weather details for a given\n",
    "city. When you need live weather data, you MUST respond with a single line that starts with\n",
    "TOOL_CALL: followed by a JSON object with the keys `name` and `args`.\n",
    "Example: TOOL_CALL:{\"name\": \"get_current_weather\", \"args\": {\"city\": \"San Diego\"}}\n",
    "Do NOT include any additional explanation when making a tool call. If you can answer without\n",
    "calling the tool (general guidance), return a normal assistant response.\n",
    "Use the function `get_current_weather(city: str, unit: str = \"celsius\")` when requesting live data.\n",
    "\"\"\"\n",
    "\n",
    "USER_QUESTION = \"What is the weather in San Francisco today?\"\n",
    "\n",
    "# Messages list we will send to the LLM. The model should decide whether to call the tool.\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": USER_QUESTION}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eebb062",
   "metadata": {},
   "source": [
    "Now that you have defined a tool and shown the model how to use it, the next step is to call the LLM using your prompt.\n",
    "\n",
    "Start the **Ollama** server in a terminal with `ollama serve`. This launches a local API endpoint that listens for LLM requests. Once the server is running, return to the notebook and in the next cell send a query to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027cb75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-63', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='TOOL_CALL:{\"name\": \"get_current_weather\", \"args\": {\"city\": \"San Francisco\"}}\\n', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1761180177, model='gemma3:1b', object='chat.completion', service_tier=None, system_fingerprint='fp_ollama', usage=CompletionUsage(completion_tokens=26, prompt_tokens=188, total_tokens=214, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 3: Call the LLM with your prompt\n",
    "# ---------------------------------------------------------\n",
    "# Task:\n",
    "#   Send SYSTEM_PROMPT + USER_QUESTION to the model.\n",
    "#\n",
    "# Steps:\n",
    "#   1. Use the Ollama client to create a chat completion. \n",
    "#       - You may find some examples here: https://platform.openai.com/docs/guides/text\n",
    "#       - If you are unsure, search the web for \"client.chat.completions.create\"\n",
    "#   2. Print the raw response.\n",
    "#\n",
    "# Expected:\n",
    "#   The model should return something like:\n",
    "#   TOOL_CALL: {\"name\": \"get_current_weather\", \"args\": {\"city\": \"San Diego\"}}\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Send the prompt to the LLM and print the raw response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemma3:1b\",\n",
    "    messages=messages,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Print the raw response from the model\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94aeb4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool `get_current_weather` with args {'city': 'San Francisco'}\n",
      "Result: It is 37°C and sunny in San Francisco.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 4: Parse the LLM output and call the tool\n",
    "# ---------------------------------------------------------\n",
    "# Task:\n",
    "#   Detect when the model requests a tool, extract its name and arguments,\n",
    "#   and execute the corresponding function.\n",
    "#\n",
    "# Steps:\n",
    "#   1. Search for the text pattern \"TOOL_CALL:{...}\" in the model output.\n",
    "#   2. Parse the JSON inside it to get the tool name and args.\n",
    "#   3. Call the matching function (e.g., get_current_weather).\n",
    "#\n",
    "# Expected:\n",
    "#   You should see a line like:\n",
    "#       Calling tool `get_current_weather` with args {'city': 'San Diego'}\n",
    "#       Result: It is 23°C and sunny in San Diego.\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "import re, json\n",
    "\n",
    "\n",
    "# Example: response.choices[0].message.content contains the model output\n",
    "output_text = response.choices[0].message.content if hasattr(response.choices[0], 'message') else str(response)\n",
    "\n",
    "# Search for TOOL_CALL pattern\n",
    "match = re.search(r'TOOL_CALL\\s*:(\\{.*\\})', output_text)\n",
    "if match:\n",
    "    tool_call_json = match.group(1)\n",
    "    try:\n",
    "        tool_call = json.loads(tool_call_json)\n",
    "        tool_name = tool_call.get('name')\n",
    "        tool_args = tool_call.get('args', {\"San Fran\", \"celsius\"})\n",
    "        print(f\"Calling tool `{tool_name}` with args {tool_args}\")\n",
    "        if tool_name == 'get_current_weather':\n",
    "            result = get_current_weather(**tool_args)\n",
    "            print(f\"Result: {result}\")\n",
    "        else:\n",
    "            print(f\"Unknown tool: {tool_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing TOOL_CALL JSON: {e}\")\n",
    "else:\n",
    "    print(\"No TOOL_CALL found in model output.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be26661",
   "metadata": {},
   "source": [
    "# 3- Standadize tool calling\n",
    "\n",
    "So far, we handled tool calling manually by writing one regex and one hard-coded function. This approach does not scale if we want to add more tools. Adding more tools would mean more `if/else` blocks and manual edits to the `TOOL_SPEC` prompt.\n",
    "\n",
    "To make the system flexible, we can standardize tool definitions by automatically reading each function’s signature, converting it to a JSON schema, and passing that schema to the LLM. This way, the LLM can dynamically understand which tools exist and how to call them without requiring manual updates to prompts or conditional logic.\n",
    "\n",
    "Next, you will implement a small helper that extracts metadata from functions and builds a schema for each tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce911b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Return a short, human-readable weather sentence for `city`.',\n",
      " 'name': 'get_current_weather',\n",
      " 'parameters': {'city': {'description': 'The city parameter',\n",
      "                         'required': True,\n",
      "                         'type': 'str'},\n",
      "                'unit': {'default': 'celsius',\n",
      "                         'description': 'The unit parameter',\n",
      "                         'required': False,\n",
      "                         'type': 'str'}},\n",
      " 'returns': {'description': 'The return value', 'type': 'str'}}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Generate a JSON schema for a tool automatically\n",
    "# ---------------------------------------------------------\n",
    "#\n",
    "# Steps:\n",
    "#   1. Use `inspect.signature` to get function parameters.\n",
    "#   2. For each argument, record its name, type, and description.\n",
    "#   3. Build a schema containing:\n",
    "#   4. Test your helper on `get_current_weather` and print the result.\n",
    "#\n",
    "# Expected:\n",
    "#   A dictionary describing the tool (its name, args, and types).\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "from pprint import pprint\n",
    "import inspect\n",
    "\n",
    "\n",
    "def to_schema(fn):\n",
    "    \"\"\"Convert a Python function to a JSON schema for tool calling.\"\"\"\n",
    "    # Get function signature and docstring\n",
    "    sig = inspect.signature(fn)\n",
    "    doc = fn.__doc__ or \"\"\n",
    "    \n",
    "    # Build parameters schema\n",
    "    params = {}\n",
    "    for name, param in sig.parameters.items():\n",
    "        param_type = param.annotation.__name__ if param.annotation != inspect.Parameter.empty else \"string\"\n",
    "        params[name] = {\n",
    "            \"type\": param_type,\n",
    "            \"description\": f\"The {name} parameter\",\n",
    "            \"required\": param.default == inspect.Parameter.empty\n",
    "        }\n",
    "        if param.default != inspect.Parameter.empty:\n",
    "            params[name][\"default\"] = param.default\n",
    "    \n",
    "    # Build complete schema\n",
    "    schema = {\n",
    "        \"name\": fn.__name__,\n",
    "        \"description\": doc.strip(),\n",
    "        \"parameters\": params,\n",
    "        \"returns\": {\n",
    "            \"type\": sig.return_annotation.__name__ if sig.return_annotation != inspect.Parameter.empty else \"string\",\n",
    "            \"description\": \"The return value\"\n",
    "        }\n",
    "    }\n",
    "    return schema\n",
    "\n",
    "# Test the schema generator with our weather function\n",
    "tool_schema = to_schema(get_current_weather)\n",
    "pprint(tool_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1163f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "TOOL_CALL:get_current_weather(city: \"Paris\", unit: \"celsius\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Provide the tool schema to the model\n",
    "# ---------------------------------------------------------\n",
    "# Goal:\n",
    "#   Give the model a \"menu\" of available tools so it can choose\n",
    "#   which one to call based on the user's question.\n",
    "#\n",
    "# Steps:\n",
    "#   1. Add an extra system message (e.g., name=\"tool_spec\")\n",
    "#      containing the JSON schema(s) of your tools.\n",
    "#   2. Include SYSTEM_PROMPT and the user question as before.\n",
    "#   3. Send the messages to the model (e.g., gemma3:1b).\n",
    "#   4. Print the raw model output to see if it picks the right tool.\n",
    "#\n",
    "# Expected:\n",
    "#   The model should produce a structured TOOL_CALL indicating\n",
    "#   which tool to use and with what arguments.\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Get the schema for our weather tool\n",
    "tool_schema = to_schema(get_current_weather)\n",
    "\n",
    "# Create messages list with tool specification\n",
    "messages_with_schema = [\n",
    "    {\"role\": \"system\", \"name\": \"tool_spec\", \"content\": f\"Available tools:\\n{json.dumps(tool_schema, indent=2)}\"},\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Paris today?\"}\n",
    "]\n",
    "\n",
    "# Call the LLM with the enhanced prompt\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemma3:1b\",\n",
    "    messages=messages_with_schema,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Print the response to see if it uses the schema correctly\n",
    "print(\"Model Response:\")\n",
    "print(response.choices[0].message.content if hasattr(response.choices[0], 'message') else response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8ec86e",
   "metadata": {},
   "source": [
    "## 4- LangChain for Tool Calling\n",
    "So far, you built a simple tool-calling pipeline manually. While this helps you understand the logic, it does not scale well when working with multiple tools, complex parsing, or multi-step reasoning.\n",
    "\n",
    "LangChain simplifies this process. You only need to declare your tools, and its *Agent* abstraction handles when to call a tool, how to use it, and how to continue reasoning afterward.\n",
    "\n",
    "In this section, you will use the **ReAct** Agent (Reasoning + Acting). It alternates between reasoning steps and tool use, producing clearer and more reliable results. We will explore reasoning-focused models in more depth next week.\n",
    "\n",
    "The following links might be helpful:\n",
    "- https://python.langchain.com/api_reference/langchain/agents/langchain.agents.initialize.initialize_agent.html\n",
    "- https://python.langchain.com/docs/integrations/tools/\n",
    "- https://python.langchain.com/docs/integrations/chat/ollama/\n",
    "- https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.LLM.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c609d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 1: Define tools for LangChain\n",
    "# ---------------------------------------------------------\n",
    "# Goal:\n",
    "#   Convert your weather function into a LangChain-compatible tool.\n",
    "#\n",
    "# Steps:\n",
    "#   1. Import `tool` from `langchain.tools`.\n",
    "#   2. Keep your existing `get_current_weather` helper as before.\n",
    "#   3. Create a new function (e.g., get_weather) that calls it.\n",
    "#   4. Add the `@tool` decorator so LangChain can register it automatically.\n",
    "#\n",
    "# Notes:\n",
    "#   • The decorator converts your Python function into a standardized tool object.\n",
    "#   • Start with keeping the logic simple and offline-friendly.\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Define a plain Python wrapper (NOT decorated) so we can register a clean\n",
    "# Tool.from_function(...) with explicit parameter names. Decorating with\n",
    "# @tool can create a different wrapper that leads to signature mismatches.\n",
    "def get_weather(city: str, unit: str = \"celsius\") -> str:\n",
    "    \"\"\"Wrapper that forwards to get_current_weather (plain function).\"\"\"\n",
    "    return get_current_weather(city, unit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9552348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered tool: get_weather - Get current weather for a city\n",
      "Using AgentType: AgentType.OPENAI_FUNCTIONS\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need a little more information to answer that for you! I don’t have real-time access to weather forecasts. \n",
      "\n",
      "**To tell you if you need an umbrella in New York today, I need to know:**\n",
      "\n",
      "*   **What is the current weather forecast for New York?** (Please provide a link to a reliable weather source like Google Weather, AccuWeather, or The Weather Channel.)\n",
      "\n",
      "Once you give me that, I can tell you if it’s likely to rain and whether you should bring an umbrella.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I need a little more information to answer that for you! I don’t have real-time access to weather forecasts. \n",
      "\n",
      "**To tell you if you need an umbrella in New York today, I need to know:**\n",
      "\n",
      "*   **What is the current weather forecast for New York?** (Please provide a link to a reliable weather source like Google Weather, AccuWeather, or The Weather Channel.)\n",
      "\n",
      "Once you give me that, I can tell you if it’s likely to rain and whether you should bring an umbrella.\n",
      "\u001b[32;1m\u001b[1;3mI need a little more information to answer that for you! I don’t have real-time access to weather forecasts. \n",
      "\n",
      "**To tell you if you need an umbrella in New York today, I need to know:**\n",
      "\n",
      "*   **What is the current weather forecast for New York?** (Please provide a link to a reliable weather source like Google Weather, AccuWeather, or The Weather Channel.)\n",
      "\n",
      "Once you give me that, I can tell you if it’s likely to rain and whether you should bring an umbrella.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I need a little more information to answer that for you! I don’t have real-time access to weather forecasts. \n",
      "\n",
      "**To tell you if you need an umbrella in New York today, I need to know:**\n",
      "\n",
      "*   **What is the current weather forecast for New York?** (Please provide a link to a reliable weather source like Google Weather, AccuWeather, or The Weather Channel.)\n",
      "\n",
      "Once you give me that, I can tell you if it’s likely to rain and whether you should bring an umbrella.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 2: Initialize the LangChain Agent\n",
    "# ---------------------------------------------------------\n",
    "# Goal:\n",
    "#   Connect your tool to a local LLM using LangChain’s ReAct-style agent.\n",
    "#\n",
    "# Steps:\n",
    "#   1. Import the required classes:\n",
    "#        - ChatOllama (for local model access)\n",
    "#        - initialize_agent, Tool, AgentType\n",
    "#   2. Create an LLM instance (e.g., model=\"gemma3:1b\", temperature=0).\n",
    "#   3. Add your tool(s) to a list\n",
    "#   4. Initialize the agent using initialize_agent\n",
    "#   5. Test the agent with a natural question (e.g., \"Do I need an umbrella in Seattle today?\").\n",
    "#\n",
    "# Expected:\n",
    "#   The model should reason through the question, call your tool,\n",
    "#   and produce a final answer in plain language.\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "\n",
    "# Create a ChatOllama LLM instance pointing to the local Ollama API\n",
    "llm = ChatOllama(model=\"gemma3:1b\", temperature=0)\n",
    "\n",
    "# Wrap the Python function as a LangChain Tool using the original, typed function\n",
    "# This ensures LangChain knows the parameter names and won't fall back to a\n",
    "# generic `tool_input` signature that can confuse the agent.\n",
    "weather_tool = Tool.from_function(get_weather, name=\"get_weather\", description=\"Get current weather for a city\")\n",
    "print(f\"Registered tool: {weather_tool.name} - {weather_tool.description}\")\n",
    "\n",
    "# Some LangChain versions use different AgentType enum members. Try the preferred name\n",
    "# and fall back to a commonly available alternative to avoid AttributeError.\n",
    "try:\n",
    "    agent_type = AgentType.REACT_DESCRIPTION\n",
    "except AttributeError:\n",
    "    try:\n",
    "        agent_type = AgentType.OPENAI_FUNCTIONS # ZERO_SHOT_REACT_DESCRIPTION\n",
    "    except AttributeError:\n",
    "        # As a last resort, use the first available AgentType enum member\n",
    "        agent_type = list(AgentType)[0]\n",
    "\n",
    "print(f\"Using AgentType: {agent_type}\")\n",
    "\n",
    "agent_prompt = \"\"\"\n",
    "Use the following format for all tool use:\n",
    "\n",
    "Thought: your reasoning\n",
    "Action: the tool you want to use\n",
    "Action Input: input to that tool\n",
    "Observation: result from the tool\n",
    "\n",
    "Repeat Thought/Action/Action Input/Observation as needed.\n",
    "End with:\n",
    "Thought: Final Answer.\n",
    "Final Answer: your answer\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the agent with the tool\n",
    "agent = initialize_agent(\n",
    "    tools=[weather_tool],\n",
    "    llm=llm,\n",
    "    agent=agent_type,\n",
    "    agent_prompt=agent_prompt,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# Example run (commented out by default; uncomment to test)\n",
    "result = agent.run(\"Do I need an umbrella in New York today?\", )\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9e8fb",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "\n",
    "The console log displays the **Thought → Action → Observation → …** loop until the agent produces its final answer. Because `verbose=True`, LangChain prints each intermediate reasoning step.\n",
    "\n",
    "If you want to add more tools, simply append them to the tools list. LangChain will handle argument validation, schema generation, and tool-calling logic automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5- Perplexity‑Style Web Search\n",
    "Agents become much more powerful when they can look up real information on the web instead of relying only on their internal knowledge.\n",
    "\n",
    "In this section, you will combine everything you have learned to build a simple Ask-the-Web Agent. You will integrate a web search tool (DuckDuckGo) and make it available to the agent using the same tool-calling approach as before.\n",
    "\n",
    "This will let the model retrieve fresh results, reason over them, and generate an informed answer—similar to how Perplexity works.\n",
    "\n",
    "You may find some examples from the following links:\n",
    "- https://pypi.org/project/duckduckgo-search/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Google News - Artificial intelligence - Latest\n",
      "   https://news.google.com/topics/CAAqJAgKIh5DQkFTRUFvSEwyMHZNRzFyZWhJRlpXNHRSMElvQUFQAQ\n",
      "   Read full articles, watch videos, browse thousands of titles and more on the \"Artificialintelligence\" topic with Google News.\n",
      "\n",
      "2. Meta AI layoffs today: 600 jobs are already being cut from ...\n",
      "   https://www.fastcompany.com/91427041/meta-ai-layoffs-today-600-jobs-are-already-being-cut-from-alexandr-wang-superintelligence-lab\n",
      "   1 day ago · According to a memo from Wang, the move means 'fewer conversations will be required to make a decision' as the tech giant ramps up artificial intelligence.\n",
      "\n",
      "3. AI News & Artificial Intelligence | TechCrunch\n",
      "   https://techcrunch.com/category/artificial-intelligence/\n",
      "   Read the latest on artificialintelligence and machine learning tech, the companies that are building them, and the ethical issues AI raises today.\n",
      "\n",
      "4. Meta cutting 600 AI jobs even as it continues to hire more ...\n",
      "   https://apnews.com/article/meta-ai-layoffs-600-artificial-intelligence-7f7b77ba002f7095984f17ebd034bf60\n",
      "   7 hours ago · Meta Platforms is cutting roughly 600 artificial intelligence jobs even as it continues to hire more workers for its superintelligence lab, the company confirmed on Wednesday.\n",
      "\n",
      "5. AI News | Latest AI News, Analysis & Events\n",
      "   https://www.artificialintelligence-news.com/\n",
      "   6 days ago · AINews reports on the latest artificial intelligence news and insights. Explore industry trends from the frontline of AI.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 1: Add a web search tool\n",
    "# ---------------------------------------------------------\n",
    "# Goal:\n",
    "#   Create a tool that lets the agent search the web and return results.\n",
    "#\n",
    "# Steps:\n",
    "#   1. Use DuckDuckGo for quick, open web searches.\n",
    "#   2. Write a helper function (e.g., search_web) that:\n",
    "#        • Takes a query string\n",
    "#        • Uses DDGS to fetch top results (titles + URLs)\n",
    "#        • Returns them as a formatted string\n",
    "#   3. Wrap it with the @tool decorator to make it available to LangChain.\n",
    "\n",
    "\n",
    "from ddgs import DDGS as ddgs\n",
    "from langchain.tools import tool\n",
    "# We decorate the function with @tool so LangChain can also discover it via\n",
    "# the decorator-based registration. We still unwrap the original function\n",
    "# when creating a Tool.from_function to preserve the typed signature.\n",
    "\n",
    "@tool\n",
    "def search_web(query: str, max_results: int = 5) -> str:\n",
    "    \"\"\"Search the web (DuckDuckGo) and return a short formatted summary.\"\"\"\n",
    "    try:\n",
    "        # Use the DDGS context manager for reliable connection handling\n",
    "        with DDGS() as ddgs:\n",
    "            # Get search results as a list (the _search method is more reliable)\n",
    "            results = list(ddgs.text(query, max_results=max_results))\n",
    "            \n",
    "        if not results:\n",
    "            return \"No results found.\"\n",
    "\n",
    "        out_lines = []\n",
    "        for i, r in enumerate(results[:max_results], start=1):\n",
    "            # Results dictionaries differ slightly between APIs; handle common keys\n",
    "            title = r.get('title') or r.get('text') or r.get('body') or ''\n",
    "            url = r.get('href') or r.get('url') or r.get('link') or ''\n",
    "            snippet = r.get('body') or r.get('snippet') or r.get('text') or ''\n",
    "            out_lines.append(f\"{i}. {title}\")\n",
    "            if url:\n",
    "                out_lines.append(f\"   {url}\")\n",
    "            if snippet:\n",
    "                # Keep snippet short (200 chars)\n",
    "                out_lines.append(f\"   {snippet[:200].strip()}\")\n",
    "            out_lines.append(\"\")\n",
    "        return '\\n'.join(out_lines).strip()\n",
    "    except Exception as e:\n",
    "        # Return the error as a string so the agent can observe it instead of crashing\n",
    "        return f\"search_web error: {e}\"\n",
    "\n",
    "# Example usage (run in your kernel to test):\n",
    "print(search_web.invoke('AI news today', max_results=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered tools: get_weather, search_web\n",
      "Using AgentType: AgentType.OPENAI_FUNCTIONS\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mOkay, let's dive into events happening in NYC this week! Here’s a breakdown of what’s happening, with a focus on free options. Keep in mind that event listings change *quickly*, so this is based on the most current information available as of today, October 26, 2023. **Please check the official websites for the most up-to-date details before heading out!**\n",
      "\n",
      "**Here’s a list of events, categorized by type, with a focus on free options:**\n",
      "\n",
      "**1. Free & Community Events:**\n",
      "\n",
      "* **Park Events:** NYC Parks regularly hosts free events in parks throughout the city. Check the NYC Parks website ([https://www.nyc.gov/site/parks/index.section?page=events](https://www.nyc.gov/site/parks/index.section?page=events)) for a calendar of events happening this week.  Look for things like:\n",
      "    * **Free Concerts:** Often in Central Park or other parks.\n",
      "    * **Outdoor Movie Nights:**  Various locations.\n",
      "    * **Family Fun Days:**  Check for events at smaller parks.\n",
      "* **Community Boards:**  NYC has numerous community boards (like the one in Washington Square Park) that post free events.  Check them regularly!\n",
      "* **Libraries:** Many libraries offer free activities, including story times, workshops, and lectures. Check your local library’s calendar: [https://www.nyc.gov/site/library/events/](https://www.nyc.gov/site/library/events/)\n",
      "* **Free Museum Days:**  Some museums offer free admission on certain days or evenings.  Check the websites of museums like the Metropolitan Museum of Art, the Museum of Modern Art (MoMA), and the American Museum of Natural History. (Note:  Some museums have timed entry, so plan ahead!)\n",
      "\n",
      "**2. Music & Performances:**\n",
      "\n",
      "* **Free Concerts:**  Many venues offer free concerts, especially during the warmer months.  Check listings like:\n",
      "    * **NYC Music:** [https://www.nyc.gov/site/music/](https://www.nyc.gov/site/music/) - This is a great resource for finding events across all genres.\n",
      "    * **Resident Advisor:** [https://www.residentadvisor.com/](https://www.residentadvisor.com/) -  Focuses on electronic music events.\n",
      "* **Free Performances at Public Spaces:**  Look for performances in parks, plazas, and other public areas.\n",
      "\n",
      "**3. Arts & Culture:**\n",
      "\n",
      "* **Street Art Tours:** Several companies offer free walking tours that highlight NYC street art.\n",
      "* **Gallery Openings:** Many galleries host free openings and events.\n",
      "* **Free Art Exhibits:** Check out the websites of art museums and galleries for free exhibits.\n",
      "\n",
      "**4. Specific Neighborhood Events:**\n",
      "\n",
      "* **Brooklyn:** Check out events in Williamsburg, Bushwick, and other Brooklyn neighborhoods.\n",
      "* **Bronx:** Look for free events at the Bronx Botanical Garden or in parks.\n",
      "\n",
      "**Resources for Finding More Events:**\n",
      "\n",
      "* **Time Out New York:** [https://www.timeout.com/new-york/events](https://www.timeout.com/new-york/events) - A comprehensive guide to events in NYC.\n",
      "* **NYC.gov:** [https://www.nyc.gov/site/gov/](https://www.nyc.gov/site/gov/) - Official city government website with event listings.\n",
      "* **Eventbrite:** [https://www.eventbrite.com/](https://www.eventbrite.com/) -  A platform for finding a wide variety of events.\n",
      "\n",
      "**To help me narrow down the *best* recommendations for *you*, could you tell me:**\n",
      "\n",
      "*   **What are your interests?** (e.g., music, art, food, family activities, etc.)\n",
      "*   **What neighborhood are you interested in?** (e.g., Greenwich Village, Brooklyn, Upper West Side)\n",
      "*   **Are you looking for something specific?** (e.g., kid-friendly, outdoor, late-night)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Okay, let's dive into events happening in NYC this week! Here’s a breakdown of what’s happening, with a focus on free options. Keep in mind that event listings change *quickly*, so this is based on the most current information available as of today, October 26, 2023. **Please check the official websites for the most up-to-date details before heading out!**\n",
      "\n",
      "**Here’s a list of events, categorized by type, with a focus on free options:**\n",
      "\n",
      "**1. Free & Community Events:**\n",
      "\n",
      "* **Park Events:** NYC Parks regularly hosts free events in parks throughout the city. Check the NYC Parks website ([https://www.nyc.gov/site/parks/index.section?page=events](https://www.nyc.gov/site/parks/index.section?page=events)) for a calendar of events happening this week.  Look for things like:\n",
      "    * **Free Concerts:** Often in Central Park or other parks.\n",
      "    * **Outdoor Movie Nights:**  Various locations.\n",
      "    * **Family Fun Days:**  Check for events at smaller parks.\n",
      "* **Community Boards:**  NYC has numerous community boards (like the one in Washington Square Park) that post free events.  Check them regularly!\n",
      "* **Libraries:** Many libraries offer free activities, including story times, workshops, and lectures. Check your local library’s calendar: [https://www.nyc.gov/site/library/events/](https://www.nyc.gov/site/library/events/)\n",
      "* **Free Museum Days:**  Some museums offer free admission on certain days or evenings.  Check the websites of museums like the Metropolitan Museum of Art, the Museum of Modern Art (MoMA), and the American Museum of Natural History. (Note:  Some museums have timed entry, so plan ahead!)\n",
      "\n",
      "**2. Music & Performances:**\n",
      "\n",
      "* **Free Concerts:**  Many venues offer free concerts, especially during the warmer months.  Check listings like:\n",
      "    * **NYC Music:** [https://www.nyc.gov/site/music/](https://www.nyc.gov/site/music/) - This is a great resource for finding events across all genres.\n",
      "    * **Resident Advisor:** [https://www.residentadvisor.com/](https://www.residentadvisor.com/) -  Focuses on electronic music events.\n",
      "* **Free Performances at Public Spaces:**  Look for performances in parks, plazas, and other public areas.\n",
      "\n",
      "**3. Arts & Culture:**\n",
      "\n",
      "* **Street Art Tours:** Several companies offer free walking tours that highlight NYC street art.\n",
      "* **Gallery Openings:** Many galleries host free openings and events.\n",
      "* **Free Art Exhibits:** Check out the websites of art museums and galleries for free exhibits.\n",
      "\n",
      "**4. Specific Neighborhood Events:**\n",
      "\n",
      "* **Brooklyn:** Check out events in Williamsburg, Bushwick, and other Brooklyn neighborhoods.\n",
      "* **Bronx:** Look for free events at the Bronx Botanical Garden or in parks.\n",
      "\n",
      "**Resources for Finding More Events:**\n",
      "\n",
      "* **Time Out New York:** [https://www.timeout.com/new-york/events](https://www.timeout.com/new-york/events) - A comprehensive guide to events in NYC.\n",
      "* **NYC.gov:** [https://www.nyc.gov/site/gov/](https://www.nyc.gov/site/gov/) - Official city government website with event listings.\n",
      "* **Eventbrite:** [https://www.eventbrite.com/](https://www.eventbrite.com/) -  A platform for finding a wide variety of events.\n",
      "\n",
      "**To help me narrow down the *best* recommendations for *you*, could you tell me:**\n",
      "\n",
      "*   **What are your interests?** (e.g., music, art, food, family activities, etc.)\n",
      "*   **What neighborhood are you interested in?** (e.g., Greenwich Village, Brooklyn, Upper West Side)\n",
      "*   **Are you looking for something specific?** (e.g., kid-friendly, outdoor, late-night)\n",
      "\u001b[32;1m\u001b[1;3mOkay, let's dive into events happening in NYC this week! Here’s a breakdown of what’s happening, with a focus on free options. Keep in mind that event listings change *quickly*, so this is based on the most current information available as of today, October 26, 2023. **Please check the official websites for the most up-to-date details before heading out!**\n",
      "\n",
      "**Here’s a list of events, categorized by type, with a focus on free options:**\n",
      "\n",
      "**1. Free & Community Events:**\n",
      "\n",
      "* **Park Events:** NYC Parks regularly hosts free events in parks throughout the city. Check the NYC Parks website ([https://www.nyc.gov/site/parks/index.section?page=events](https://www.nyc.gov/site/parks/index.section?page=events)) for a calendar of events happening this week.  Look for things like:\n",
      "    * **Free Concerts:** Often in Central Park or other parks.\n",
      "    * **Outdoor Movie Nights:**  Various locations.\n",
      "    * **Family Fun Days:**  Check for events at smaller parks.\n",
      "* **Community Boards:**  NYC has numerous community boards (like the one in Washington Square Park) that post free events.  Check them regularly!\n",
      "* **Libraries:** Many libraries offer free activities, including story times, workshops, and lectures. Check your local library’s calendar: [https://www.nyc.gov/site/library/events/](https://www.nyc.gov/site/library/events/)\n",
      "* **Free Museum Days:**  Some museums offer free admission on certain days or evenings.  Check the websites of museums like the Metropolitan Museum of Art, the Museum of Modern Art (MoMA), and the American Museum of Natural History. (Note:  Some museums have timed entry, so plan ahead!)\n",
      "\n",
      "**2. Music & Performances:**\n",
      "\n",
      "* **Free Concerts:**  Many venues offer free concerts, especially during the warmer months.  Check listings like:\n",
      "    * **NYC Music:** [https://www.nyc.gov/site/music/](https://www.nyc.gov/site/music/) - This is a great resource for finding events across all genres.\n",
      "    * **Resident Advisor:** [https://www.residentadvisor.com/](https://www.residentadvisor.com/) -  Focuses on electronic music events.\n",
      "* **Free Performances at Public Spaces:**  Look for performances in parks, plazas, and other public areas.\n",
      "\n",
      "**3. Arts & Culture:**\n",
      "\n",
      "* **Street Art Tours:** Several companies offer free walking tours that highlight NYC street art.\n",
      "* **Gallery Openings:** Many galleries host free openings and events.\n",
      "* **Free Art Exhibits:** Check out the websites of art museums and galleries for free exhibits.\n",
      "\n",
      "**4. Specific Neighborhood Events:**\n",
      "\n",
      "* **Brooklyn:** Check out events in Williamsburg, Bushwick, and other Brooklyn neighborhoods.\n",
      "* **Bronx:** Look for free events at the Bronx Botanical Garden or in parks.\n",
      "\n",
      "**Resources for Finding More Events:**\n",
      "\n",
      "* **Time Out New York:** [https://www.timeout.com/new-york/events](https://www.timeout.com/new-york/events) - A comprehensive guide to events in NYC.\n",
      "* **NYC.gov:** [https://www.nyc.gov/site/gov/](https://www.nyc.gov/site/gov/) - Official city government website with event listings.\n",
      "* **Eventbrite:** [https://www.eventbrite.com/](https://www.eventbrite.com/) -  A platform for finding a wide variety of events.\n",
      "\n",
      "**To help me narrow down the *best* recommendations for *you*, could you tell me:**\n",
      "\n",
      "*   **What are your interests?** (e.g., music, art, food, family activities, etc.)\n",
      "*   **What neighborhood are you interested in?** (e.g., Greenwich Village, Brooklyn, Upper West Side)\n",
      "*   **Are you looking for something specific?** (e.g., kid-friendly, outdoor, late-night)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Okay, let's dive into events happening in NYC this week! Here’s a breakdown of what’s happening, with a focus on free options. Keep in mind that event listings change *quickly*, so this is based on the most current information available as of today, October 26, 2023. **Please check the official websites for the most up-to-date details before heading out!**\n",
      "\n",
      "**Here’s a list of events, categorized by type, with a focus on free options:**\n",
      "\n",
      "**1. Free & Community Events:**\n",
      "\n",
      "* **Park Events:** NYC Parks regularly hosts free events in parks throughout the city. Check the NYC Parks website ([https://www.nyc.gov/site/parks/index.section?page=events](https://www.nyc.gov/site/parks/index.section?page=events)) for a calendar of events happening this week.  Look for things like:\n",
      "    * **Free Concerts:** Often in Central Park or other parks.\n",
      "    * **Outdoor Movie Nights:**  Various locations.\n",
      "    * **Family Fun Days:**  Check for events at smaller parks.\n",
      "* **Community Boards:**  NYC has numerous community boards (like the one in Washington Square Park) that post free events.  Check them regularly!\n",
      "* **Libraries:** Many libraries offer free activities, including story times, workshops, and lectures. Check your local library’s calendar: [https://www.nyc.gov/site/library/events/](https://www.nyc.gov/site/library/events/)\n",
      "* **Free Museum Days:**  Some museums offer free admission on certain days or evenings.  Check the websites of museums like the Metropolitan Museum of Art, the Museum of Modern Art (MoMA), and the American Museum of Natural History. (Note:  Some museums have timed entry, so plan ahead!)\n",
      "\n",
      "**2. Music & Performances:**\n",
      "\n",
      "* **Free Concerts:**  Many venues offer free concerts, especially during the warmer months.  Check listings like:\n",
      "    * **NYC Music:** [https://www.nyc.gov/site/music/](https://www.nyc.gov/site/music/) - This is a great resource for finding events across all genres.\n",
      "    * **Resident Advisor:** [https://www.residentadvisor.com/](https://www.residentadvisor.com/) -  Focuses on electronic music events.\n",
      "* **Free Performances at Public Spaces:**  Look for performances in parks, plazas, and other public areas.\n",
      "\n",
      "**3. Arts & Culture:**\n",
      "\n",
      "* **Street Art Tours:** Several companies offer free walking tours that highlight NYC street art.\n",
      "* **Gallery Openings:** Many galleries host free openings and events.\n",
      "* **Free Art Exhibits:** Check out the websites of art museums and galleries for free exhibits.\n",
      "\n",
      "**4. Specific Neighborhood Events:**\n",
      "\n",
      "* **Brooklyn:** Check out events in Williamsburg, Bushwick, and other Brooklyn neighborhoods.\n",
      "* **Bronx:** Look for free events at the Bronx Botanical Garden or in parks.\n",
      "\n",
      "**Resources for Finding More Events:**\n",
      "\n",
      "* **Time Out New York:** [https://www.timeout.com/new-york/events](https://www.timeout.com/new-york/events) - A comprehensive guide to events in NYC.\n",
      "* **NYC.gov:** [https://www.nyc.gov/site/gov/](https://www.nyc.gov/site/gov/) - Official city government website with event listings.\n",
      "* **Eventbrite:** [https://www.eventbrite.com/](https://www.eventbrite.com/) -  A platform for finding a wide variety of events.\n",
      "\n",
      "**To help me narrow down the *best* recommendations for *you*, could you tell me:**\n",
      "\n",
      "*   **What are your interests?** (e.g., music, art, food, family activities, etc.)\n",
      "*   **What neighborhood are you interested in?** (e.g., Greenwich Village, Brooklyn, Upper West Side)\n",
      "*   **Are you looking for something specific?** (e.g., kid-friendly, outdoor, late-night)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------------------------------------\n",
    "# Step 2: Initialize the web-search agent\n",
    "# ---------------------------------------------------------\n",
    "# Goal:\n",
    "#   Connect your `web_search` tool to a language model\n",
    "#   so the agent can search and reason over real data.\n",
    "#\n",
    "# Steps:\n",
    "#   1. Import `initialize_agent` and `AgentType`.\n",
    "#   2. Create an LLM (e.g., ChatOllama).\n",
    "#   3. Add your `web_search` tool to the tools list.\n",
    "#   4. Initialize the agent using: initialize_agent\n",
    "#   5. Keep `verbose=True` to observe reasoning steps.\n",
    "#\n",
    "# Expected:\n",
    "#   The agent should be ready to accept user queries\n",
    "#   and use your web search tool when needed.\n",
    "# ---------------------------------------------------------\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Create local LLM\n",
    "llm = ChatOllama(model=\"gemma3:1b\", temperature=0)\n",
    "\n",
    "# The decorator (@tool) may wrap the original function. Some LangChain helpers\n",
    "# expose the original python function at attribute `func` on the decorated object;\n",
    "# fall back to the function object itself if not present.\n",
    "def unwrap_tool_fn(tool_obj):\n",
    "    return getattr(tool_obj, 'func', tool_obj)\n",
    "\n",
    "# Build Tool objects from the underlying functions (preserve typed signatures)\n",
    "weather_tool = Tool.from_function(get_current_weather, name=\"get_weather\", description=\"Get current weather for a city\")\n",
    "search_tool_fn = unwrap_tool_fn(search_web)\n",
    "web_tool = Tool.from_function(search_tool_fn, name=\"search_web\", description=\"Search the web (DuckDuckGo) and return top results\")\n",
    "print(f\"Registered tools: {weather_tool.name}, {web_tool.name}\")\n",
    "\n",
    "# Choose AgentType robustly across LangChain versions\n",
    "try:\n",
    "    agent_type = AgentType.REACT_DESCRIPTION\n",
    "except Exception:\n",
    "    try:\n",
    "        agent_type = AgentType.OPENAI_FUNCTIONS # ZERO_SHOT_REACT_DESCRIPTION\n",
    "    except Exception:\n",
    "        agent_type = list(AgentType)[0]\n",
    "print(f\"Using AgentType: {agent_type}\")\n",
    "\n",
    "# Initialize the agent with both tools\n",
    "agent = initialize_agent(\n",
    "    tools=[weather_tool, web_tool],\n",
    "    llm=llm,\n",
    "    agent=agent_type,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "# Example run (uncomment to test in your environment):\n",
    "# print(agent.run(\"Find events in NYC this week and tell me if there are any free ones.\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let’s see the agent's output in action with a real example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asking: What is the latest AI technology news as of today?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mOkay, let's dive into some of the latest AI news as of today, October 26, 2023. It’s a really dynamic field, so here’s a breakdown of key areas and developments:\n",
      "\n",
      "**1. ChatGPT & Large Language Models (LLMs) - Still Dominating the Conversation**\n",
      "\n",
      "* **OpenAI's GPT-5 Rumors & Hints:** There's *still* a lot of buzz around OpenAI's next iteration of GPT. Rumors are swirling about potential improvements to reasoning, creativity, and multi-modality (handling images, audio, and video).  While there's no official announcement yet, sources suggest it could be a significant leap.\n",
      "* **Microsoft's Integration:** Microsoft is aggressively integrating OpenAI's models into its products (Bing, Office, Windows).  They're focusing on making ChatGPT more accessible and integrated into existing workflows.\n",
      "* **Anthropic's Claude 3:** Anthropic has released Claude 3, a new LLM, that is being touted as a strong competitor to ChatGPT. It’s particularly praised for its reasoning and ability to handle complex tasks.  It comes in different versions (Opus, Sonnet, and Haiku) offering varying levels of speed and cost.\n",
      "\n",
      "**2. AI in Healthcare - Rapid Progress**\n",
      "\n",
      "* **AI-Powered Diagnostics:** Several companies are showcasing AI tools that are assisting doctors with diagnosing diseases like skin cancer, diabetic retinopathy, and even early signs of Alzheimer's.  Google and several startups are leading the charge.\n",
      "* **Drug Discovery:** AI is accelerating drug discovery by analyzing vast datasets of molecular structures and predicting potential drug candidates.\n",
      "* **Personalized Medicine:** AI is being used to tailor treatment plans based on individual patient data.\n",
      "\n",
      "\n",
      "**3. AI Safety & Regulation - Ongoing Debate**\n",
      "\n",
      "* **EU AI Act:** The European Union is finalizing its AI Act, which will regulate AI development and deployment across the EU. It’s a complex and evolving piece of legislation.\n",
      "* **Deepfakes & Misinformation:** Concerns about deepfakes and the spread of misinformation using AI are intensifying.  There's ongoing discussion about detection methods and ethical guidelines.\n",
      "* **AI Alignment:** Researchers are working on ensuring AI systems are aligned with human values and goals – a critical challenge.\n",
      "\n",
      "\n",
      "**4.  Emerging Trends & Technologies**\n",
      "\n",
      "* **Multimodal AI:**  AI models are becoming increasingly capable of understanding and generating content across multiple modalities (text, images, audio, video).  This is a huge focus.\n",
      "* **Edge AI:**  Running AI models on devices (like smartphones or cars) rather than relying solely on cloud computing is gaining traction.\n",
      "* **Generative AI for Code:** Tools like GitHub Copilot are becoming incredibly sophisticated at generating code, assisting developers.\n",
      "\n",
      "\n",
      "**5.  Specific News Highlights (as of Today):**\n",
      "\n",
      "* **Stanford University's AI Safety Research:** Stanford has released a report highlighting potential risks associated with AI and outlining research focused on mitigating those risks.\n",
      "* **Meta's AI Investments:** Meta is heavily investing in AI research and development, particularly in areas like computer vision and natural language processing.\n",
      "\n",
      "\n",
      "**Resources for Staying Updated:**\n",
      "\n",
      "* **TechCrunch:** [https://techcrunch.com/](https://techcrunch.com/)\n",
      "* **Wired:** [https://www.wired.com/](https://www.wired.com/)\n",
      "* **MIT Technology Review:** [https://www.technologyreview.com/](https://www.technologyreview.com/)\n",
      "* **Google AI Blog:** [https://ai.googleblog.com/](https://ai.googleblog.com/)\n",
      "\n",
      "---\n",
      "\n",
      "**To help me give you even *more* relevant information, could you tell me:**\n",
      "\n",
      "*   **What specific area of AI are you most interested in?** (e.g., AI in healthcare, AI safety, generative AI, etc.)\n",
      "*   **What's your current level of knowledge about AI?** (Are you a beginner, intermediate, or expert?)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "Okay, let's dive into some of the latest AI news as of today, October 26, 2023. It’s a really dynamic field, so here’s a breakdown of key areas and developments:\n",
      "\n",
      "**1. ChatGPT & Large Language Models (LLMs) - Still Dominating the Conversation**\n",
      "\n",
      "* **OpenAI's GPT-5 Rumors & Hints:** There's *still* a lot of buzz around OpenAI's next iteration of GPT. Rumors are swirling about potential improvements to reasoning, creativity, and multi-modality (handling images, audio, and video).  While there's no official announcement yet, sources suggest it could be a significant leap.\n",
      "* **Microsoft's Integration:** Microsoft is aggressively integrating OpenAI's models into its products (Bing, Office, Windows).  They're focusing on making ChatGPT more accessible and integrated into existing workflows.\n",
      "* **Anthropic's Claude 3:** Anthropic has released Claude 3, a new LLM, that is being touted as a strong competitor to ChatGPT. It’s particularly praised for its reasoning and ability to handle complex tasks.  It comes in different versions (Opus, Sonnet, and Haiku) offering varying levels of speed and cost.\n",
      "\n",
      "**2. AI in Healthcare - Rapid Progress**\n",
      "\n",
      "* **AI-Powered Diagnostics:** Several companies are showcasing AI tools that are assisting doctors with diagnosing diseases like skin cancer, diabetic retinopathy, and even early signs of Alzheimer's.  Google and several startups are leading the charge.\n",
      "* **Drug Discovery:** AI is accelerating drug discovery by analyzing vast datasets of molecular structures and predicting potential drug candidates.\n",
      "* **Personalized Medicine:** AI is being used to tailor treatment plans based on individual patient data.\n",
      "\n",
      "\n",
      "**3. AI Safety & Regulation - Ongoing Debate**\n",
      "\n",
      "* **EU AI Act:** The European Union is finalizing its AI Act, which will regulate AI development and deployment across the EU. It’s a complex and evolving piece of legislation.\n",
      "* **Deepfakes & Misinformation:** Concerns about deepfakes and the spread of misinformation using AI are intensifying.  There's ongoing discussion about detection methods and ethical guidelines.\n",
      "* **AI Alignment:** Researchers are working on ensuring AI systems are aligned with human values and goals – a critical challenge.\n",
      "\n",
      "\n",
      "**4.  Emerging Trends & Technologies**\n",
      "\n",
      "* **Multimodal AI:**  AI models are becoming increasingly capable of understanding and generating content across multiple modalities (text, images, audio, video).  This is a huge focus.\n",
      "* **Edge AI:**  Running AI models on devices (like smartphones or cars) rather than relying solely on cloud computing is gaining traction.\n",
      "* **Generative AI for Code:** Tools like GitHub Copilot are becoming incredibly sophisticated at generating code, assisting developers.\n",
      "\n",
      "\n",
      "**5.  Specific News Highlights (as of Today):**\n",
      "\n",
      "* **Stanford University's AI Safety Research:** Stanford has released a report highlighting potential risks associated with AI and outlining research focused on mitigating those risks.\n",
      "* **Meta's AI Investments:** Meta is heavily investing in AI research and development, particularly in areas like computer vision and natural language processing.\n",
      "\n",
      "\n",
      "**Resources for Staying Updated:**\n",
      "\n",
      "* **TechCrunch:** [https://techcrunch.com/](https://techcrunch.com/)\n",
      "* **Wired:** [https://www.wired.com/](https://www.wired.com/)\n",
      "* **MIT Technology Review:** [https://www.technologyreview.com/](https://www.technologyreview.com/)\n",
      "* **Google AI Blog:** [https://ai.googleblog.com/](https://ai.googleblog.com/)\n",
      "\n",
      "---\n",
      "\n",
      "**To help me give you even *more* relevant information, could you tell me:**\n",
      "\n",
      "*   **What specific area of AI are you most interested in?** (e.g., AI in healthcare, AI safety, generative AI, etc.)\n",
      "*   **What's your current level of knowledge about AI?** (Are you a beginner, intermediate, or expert?)\n",
      "\u001b[32;1m\u001b[1;3mOkay, let's dive into some of the latest AI news as of today, October 26, 2023. It’s a really dynamic field, so here’s a breakdown of key areas and developments:\n",
      "\n",
      "**1. ChatGPT & Large Language Models (LLMs) - Still Dominating the Conversation**\n",
      "\n",
      "* **OpenAI's GPT-5 Rumors & Hints:** There's *still* a lot of buzz around OpenAI's next iteration of GPT. Rumors are swirling about potential improvements to reasoning, creativity, and multi-modality (handling images, audio, and video).  While there's no official announcement yet, sources suggest it could be a significant leap.\n",
      "* **Microsoft's Integration:** Microsoft is aggressively integrating OpenAI's models into its products (Bing, Office, Windows).  They're focusing on making ChatGPT more accessible and integrated into existing workflows.\n",
      "* **Anthropic's Claude 3:** Anthropic has released Claude 3, a new LLM, that is being touted as a strong competitor to ChatGPT. It’s particularly praised for its reasoning and ability to handle complex tasks.  It comes in different versions (Opus, Sonnet, and Haiku) offering varying levels of speed and cost.\n",
      "\n",
      "**2. AI in Healthcare - Rapid Progress**\n",
      "\n",
      "* **AI-Powered Diagnostics:** Several companies are showcasing AI tools that are assisting doctors with diagnosing diseases like skin cancer, diabetic retinopathy, and even early signs of Alzheimer's.  Google and several startups are leading the charge.\n",
      "* **Drug Discovery:** AI is accelerating drug discovery by analyzing vast datasets of molecular structures and predicting potential drug candidates.\n",
      "* **Personalized Medicine:** AI is being used to tailor treatment plans based on individual patient data.\n",
      "\n",
      "\n",
      "**3. AI Safety & Regulation - Ongoing Debate**\n",
      "\n",
      "* **EU AI Act:** The European Union is finalizing its AI Act, which will regulate AI development and deployment across the EU. It’s a complex and evolving piece of legislation.\n",
      "* **Deepfakes & Misinformation:** Concerns about deepfakes and the spread of misinformation using AI are intensifying.  There's ongoing discussion about detection methods and ethical guidelines.\n",
      "* **AI Alignment:** Researchers are working on ensuring AI systems are aligned with human values and goals – a critical challenge.\n",
      "\n",
      "\n",
      "**4.  Emerging Trends & Technologies**\n",
      "\n",
      "* **Multimodal AI:**  AI models are becoming increasingly capable of understanding and generating content across multiple modalities (text, images, audio, video).  This is a huge focus.\n",
      "* **Edge AI:**  Running AI models on devices (like smartphones or cars) rather than relying solely on cloud computing is gaining traction.\n",
      "* **Generative AI for Code:** Tools like GitHub Copilot are becoming incredibly sophisticated at generating code, assisting developers.\n",
      "\n",
      "\n",
      "**5.  Specific News Highlights (as of Today):**\n",
      "\n",
      "* **Stanford University's AI Safety Research:** Stanford has released a report highlighting potential risks associated with AI and outlining research focused on mitigating those risks.\n",
      "* **Meta's AI Investments:** Meta is heavily investing in AI research and development, particularly in areas like computer vision and natural language processing.\n",
      "\n",
      "\n",
      "**Resources for Staying Updated:**\n",
      "\n",
      "* **TechCrunch:** [https://techcrunch.com/](https://techcrunch.com/)\n",
      "* **Wired:** [https://www.wired.com/](https://www.wired.com/)\n",
      "* **MIT Technology Review:** [https://www.technologyreview.com/](https://www.technologyreview.com/)\n",
      "* **Google AI Blog:** [https://ai.googleblog.com/](https://ai.googleblog.com/)\n",
      "\n",
      "---\n",
      "\n",
      "**To help me give you even *more* relevant information, could you tell me:**\n",
      "\n",
      "*   **What specific area of AI are you most interested in?** (e.g., AI in healthcare, AI safety, generative AI, etc.)\n",
      "*   **What's your current level of knowledge about AI?** (Are you a beginner, intermediate, or expert?)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "Okay, let's dive into some of the latest AI news as of today, October 26, 2023. It’s a really dynamic field, so here’s a breakdown of key areas and developments:\n",
      "\n",
      "**1. ChatGPT & Large Language Models (LLMs) - Still Dominating the Conversation**\n",
      "\n",
      "* **OpenAI's GPT-5 Rumors & Hints:** There's *still* a lot of buzz around OpenAI's next iteration of GPT. Rumors are swirling about potential improvements to reasoning, creativity, and multi-modality (handling images, audio, and video).  While there's no official announcement yet, sources suggest it could be a significant leap.\n",
      "* **Microsoft's Integration:** Microsoft is aggressively integrating OpenAI's models into its products (Bing, Office, Windows).  They're focusing on making ChatGPT more accessible and integrated into existing workflows.\n",
      "* **Anthropic's Claude 3:** Anthropic has released Claude 3, a new LLM, that is being touted as a strong competitor to ChatGPT. It’s particularly praised for its reasoning and ability to handle complex tasks.  It comes in different versions (Opus, Sonnet, and Haiku) offering varying levels of speed and cost.\n",
      "\n",
      "**2. AI in Healthcare - Rapid Progress**\n",
      "\n",
      "* **AI-Powered Diagnostics:** Several companies are showcasing AI tools that are assisting doctors with diagnosing diseases like skin cancer, diabetic retinopathy, and even early signs of Alzheimer's.  Google and several startups are leading the charge.\n",
      "* **Drug Discovery:** AI is accelerating drug discovery by analyzing vast datasets of molecular structures and predicting potential drug candidates.\n",
      "* **Personalized Medicine:** AI is being used to tailor treatment plans based on individual patient data.\n",
      "\n",
      "\n",
      "**3. AI Safety & Regulation - Ongoing Debate**\n",
      "\n",
      "* **EU AI Act:** The European Union is finalizing its AI Act, which will regulate AI development and deployment across the EU. It’s a complex and evolving piece of legislation.\n",
      "* **Deepfakes & Misinformation:** Concerns about deepfakes and the spread of misinformation using AI are intensifying.  There's ongoing discussion about detection methods and ethical guidelines.\n",
      "* **AI Alignment:** Researchers are working on ensuring AI systems are aligned with human values and goals – a critical challenge.\n",
      "\n",
      "\n",
      "**4.  Emerging Trends & Technologies**\n",
      "\n",
      "* **Multimodal AI:**  AI models are becoming increasingly capable of understanding and generating content across multiple modalities (text, images, audio, video).  This is a huge focus.\n",
      "* **Edge AI:**  Running AI models on devices (like smartphones or cars) rather than relying solely on cloud computing is gaining traction.\n",
      "* **Generative AI for Code:** Tools like GitHub Copilot are becoming incredibly sophisticated at generating code, assisting developers.\n",
      "\n",
      "\n",
      "**5.  Specific News Highlights (as of Today):**\n",
      "\n",
      "* **Stanford University's AI Safety Research:** Stanford has released a report highlighting potential risks associated with AI and outlining research focused on mitigating those risks.\n",
      "* **Meta's AI Investments:** Meta is heavily investing in AI research and development, particularly in areas like computer vision and natural language processing.\n",
      "\n",
      "\n",
      "**Resources for Staying Updated:**\n",
      "\n",
      "* **TechCrunch:** [https://techcrunch.com/](https://techcrunch.com/)\n",
      "* **Wired:** [https://www.wired.com/](https://www.wired.com/)\n",
      "* **MIT Technology Review:** [https://www.technologyreview.com/](https://www.technologyreview.com/)\n",
      "* **Google AI Blog:** [https://ai.googleblog.com/](https://ai.googleblog.com/)\n",
      "\n",
      "---\n",
      "\n",
      "**To help me give you even *more* relevant information, could you tell me:**\n",
      "\n",
      "*   **What specific area of AI are you most interested in?** (e.g., AI in healthcare, AI safety, generative AI, etc.)\n",
      "*   **What's your current level of knowledge about AI?** (Are you a beginner, intermediate, or expert?)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 3: Test your Ask-the-Web agent\n",
    "# ---------------------------------------------------------\n",
    "# Goal:\n",
    "#   Verify that the agent can search the web and return\n",
    "#   a summarized answer based on real results.\n",
    "#\n",
    "# Steps:\n",
    "#   1. Ask a natural question that requires live information,\n",
    "#      for example: \"What are the current events in San Francisco this week?\"\n",
    "#   2. Call agent.\n",
    "#\n",
    "# Expected:\n",
    "#   The agent should call `web_search`, retrieve results,\n",
    "#   and generate a short summary response.\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Test the agent with a complex query that requires web search and reasoning\n",
    "# query = \"What are the latest AI technology announcements and tell me which ones are most significant for developers as of today?\"\n",
    "query = \"What is the latest AI technology news as of today?\" # announcements and tell me which ones are most significant for developers as of today?\"\n",
    "print(\"Asking:\", query)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Run the agent and capture its response\n",
    "response = agent.run(query)\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(\"-\" * 80)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6- A minimal UI\n",
    "This project includes a simple **React** front end that sends the user’s question to a FastAPI back end and streams the agent’s response in real time. To run the UI:\n",
    "\n",
    "1- Open a terminal and start the Ollama server: `ollama serve`.\n",
    "\n",
    "2- In a second terminal, navigate to the frontend folder and install dependencies:`npm install`.\n",
    "\n",
    "3- In the same terminal, start the FastAPI back‑end: `uvicorn app:app --reload --port 8000`\n",
    "\n",
    "4- Open a third terminal, stay in the frontend folder, and start the React dev server: `npm run dev`\n",
    "\n",
    "5- Visit `http://localhost:5173/` in your browser.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 🎉 Congratulations!\n",
    "\n",
    "* You have built a **web‑enabled agent**: tool calling → JSON schema → LangChain ReAct → web search → simple UI.\n",
    "* Try adding more tools, such as news or finance APIs.\n",
    "* Experiment with multiple tools, different models, and measure accuracy vs. hallucination.\n",
    "\n",
    "\n",
    "👏 **Great job!** Take a moment to celebrate. The techniques you implemented here power many production agents and chatbots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_agent",
   "language": "python",
   "name": "web_agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
